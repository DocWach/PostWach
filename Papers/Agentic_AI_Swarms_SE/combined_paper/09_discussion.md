# Section IX: Discussion

**Target length:** ~600 words
**Status:** Draft v0.1
**Format:** IEEE Systems Journal

---

## IX. DISCUSSION

### A. Implications for SE Practice

The framework presented suggests several implications for systems engineering practice:

**Augmentation, not replacement.** Agentic AI swarms are positioned to augment human systems engineers, not replace them. The framework identifies tasks where AI swarms add value (parallel analysis, comprehensive coverage, artifact generation) while recognizing activities requiring human judgment (stakeholder engagement, creative insight, accountability). Organizations should approach AI swarms as force multipliers rather than substitutes for engineering expertise.

**Process adaptation.** Effective use of AI swarms may require adaptations to traditional SE processes. Sequential review gates designed for human-paced work may not suit rapid AI-generated analysis. Organizations may need new review approaches, quality criteria, and approval workflows suited to human-AI collaborative outputs.

**Skill evolution.** Systems engineers working with AI swarms need new competencies: formulating effective prompts, evaluating AI outputs, managing swarm configurations, and intervening appropriately. Engineering education and professional development must evolve to prepare practitioners for collaborative practice.

### B. Implications for SE Research

This work identifies several research opportunities:

**Empirical validation.** The framework is conceptual; empirical studies are needed to validate effectiveness claims. Controlled experiments comparing swarm-assisted versus traditional approaches, field studies in operational environments, and longitudinal tracking would strengthen the evidence base.

**Formalization.** More rigorous formal treatment—using established formalisms from multi-agent systems, coordination theory, and systems engineering ontologies—would enable precise reasoning about swarm properties and support formal verification of swarm behavior.

**Tool development.** Practical adoption requires tools supporting swarm configuration, execution, monitoring, and analysis. Research into tool architectures, user interfaces, and integration with existing SE tool chains would accelerate adoption.

### C. Relationship to Digital Engineering and MBSE

Agentic AI swarms emerge as digital engineering transformation advances across SE organizations. Model-Based Systems Engineering (MBSE) establishes authoritative system models as the primary communication means among disciplines [17, 18]. AI swarms could participate in this model-centric ecosystem:

- Swarms consume system models, analyze properties, and generate derived artifacts
- Shared system models serve as coordination substrate for swarm state
- Model-based traceability supports governance and audit requirements

Organizations advancing MBSE maturity are positioning themselves for AI swarm adoption. Conversely, AI capabilities create new value from MBSE investments. The synergy suggests coordinated advancement of digital engineering and AI adoption strategies.

The Department of Defense Digital Engineering Strategy [53], NASA's digital transformation initiatives, and industry digital engineering programs create infrastructure that AI swarms can leverage. Organizations should view these initiatives as complementary—digital foundations enabling AI augmentation.

### D. Limitations

This work has several limitations:

1. **Conceptual framework.** The mapping and analysis are conceptual rather than empirically validated. Actual effectiveness requires demonstration through controlled studies and field deployment.

2. **Technology maturity.** Agentic AI swarms are early-stage technology. Capabilities and limitations evolve rapidly; assessments may require revision as technology matures.

3. **Domain generalization.** While intended as domain-agnostic, examples and analysis reflect experience primarily in aerospace and defense. Applicability to other domains requires validation.

4. **Single perspective.** This paper presents one architectural approach. Alternative frameworks may prove more effective for specific contexts.

5. **Limited empirical grounding.** The maturity assessments are based on literature review rather than systematic empirical survey.

These limitations should inform interpretation and suggest directions for follow-on research.

---

**Word count:** ~560 words
**Subsections:** 4

---

## Revision Notes

- [ ] Add specific MBSE tool references
- [ ] Consider expanding digital engineering discussion
- [ ] May trim if total length exceeds target

