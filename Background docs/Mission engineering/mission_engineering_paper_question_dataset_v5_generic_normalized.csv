PaperKey,QuestionID,Year,Venue,VenueType,Title,Authors,DomainTopic,ScenarioType,MethodsUsed,Artifacts,ImpliedQuestions,PrimarySecondary,QuestionCategory,MetamodelTags,MoEs,MoPs,EvidenceType,Reproducibility,Access,SecurityLevel,DecisionType,ModelType,SourceURL,Citation,DomainSpecificHits,IsLikelyDomainSpecific,ImpliedQuestions_GenericDraft,GenericizationChanged,GenericQuestion,QuestionTemplate,InstantiationNotes,InstantiatedQuestion,GenericAcronymFlag
B2-SE-CASE-2007,B2-SE-CASE-2007-Q01,2007,AFIT / DTIC,Case Study (Technical Report),B-2 Systems Engineering Case Study (DTIC ADA464771),Griffin; Kinnu; (ed. Colombi),B-2 bomber development; systems engineering practices,Acquisition program lifecycle (historical),Retrospective case study; interviews; Friedman-Sage framework (implied),Case study report; program history; risk management examples; baseline management practices,How can a program maintain a single authoritative technical baseline across government/contractor teams to manage major redesigns without losing control?,Primary,Baseline & configuration management,Configuration; Baseline; Stakeholder; Artifact; Change; Traceability,Program stability; reduced rework,Configuration control cycle time; rework rates,Interviews + archival program documents,High (full report openly available),Open (PDF via Internet Archive),Public,Program management; technical baseline; risk management,SE process case (qualitative + quantitative baseline artifacts),https://archive.org/download/DTIC_ADA464771/DTIC_ADA464771.pdf,"Griffin, J. M., & Kinnu, J. E. (2007). B-2 Systems Engineering Case Study (ADA464771). Air Force Center for Systems Engineering, AFIT.",[],False,How can a program maintain a single authoritative technical baseline across government/contractor teams to manage major redesigns without losing control?,False,How can a program maintain a single authoritative technical baseline across government/contractor teams to manage major redesigns without losing control?,How,DomainTopic=B-2 bomber development; systems engineering practices | ScenarioType=Acquisition program lifecycle (historical) | Hits=[],How can a program maintain a single authoritative technical baseline across government/contractor teams to manage major redesigns without losing control?,False
B2-SE-CASE-2007,B2-SE-CASE-2007-Q02,2007,AFIT / DTIC,Case Study (Technical Report),B-2 Systems Engineering Case Study (DTIC ADA464771),Griffin; Kinnu; (ed. Colombi),B-2 bomber development; systems engineering practices,Acquisition program lifecycle (historical),Retrospective case study; interviews; Friedman-Sage framework (implied),Case study report; program history; risk management examples; baseline management practices,"What risk-reduction activities should be prioritized prior to key reviews (e.g., PDR) to retire the highest-impact technical risks?",Primary,Risk management & technical reviews,Risk; Review; Verification; Mitigation; Measure,Reduced technical risk at review,Risk closure burn-down; test coverage,Interviews + archival program documents,High (full report openly available),Open (PDF via Internet Archive),Public,Program management; technical baseline; risk management,SE process case (qualitative + quantitative baseline artifacts),https://archive.org/download/DTIC_ADA464771/DTIC_ADA464771.pdf,"Griffin, J. M., & Kinnu, J. E. (2007). B-2 Systems Engineering Case Study (ADA464771). Air Force Center for Systems Engineering, AFIT.",[],False,"What risk-reduction activities should be prioritized prior to key reviews (e.g., PDR) to retire the highest-impact technical risks?",False,"What risk-reduction activities should be prioritized prior to key reviews (e.g., PDR) to retire the highest-impact technical risks?",What,DomainTopic=B-2 bomber development; systems engineering practices | ScenarioType=Acquisition program lifecycle (historical) | Hits=[],"What risk-reduction activities should be prioritized prior to key reviews (e.g., PDR) to retire the highest-impact technical risks?",True
B2-SE-CASE-2007,B2-SE-CASE-2007-Q03,2007,AFIT / DTIC,Case Study (Technical Report),B-2 Systems Engineering Case Study (DTIC ADA464771),Griffin; Kinnu; (ed. Colombi),B-2 bomber development; systems engineering practices,Acquisition program lifecycle (historical),Retrospective case study; interviews; Friedman-Sage framework (implied),Case study report; program history; risk management examples; baseline management practices,Which systems engineering practices most strongly correlate with achieving performance objectives while controlling cost/schedule in complex programs?,Primary,SE practice effectiveness,Process; Measure; Cost; Schedule; Performance; Stakeholder,Delivered capability vs objectives,Schedule variance; cost variance; TPMs,Interviews + archival program documents,High (full report openly available),Open (PDF via Internet Archive),Public,Program management; technical baseline; risk management,SE process case (qualitative + quantitative baseline artifacts),https://archive.org/download/DTIC_ADA464771/DTIC_ADA464771.pdf,"Griffin, J. M., & Kinnu, J. E. (2007). B-2 Systems Engineering Case Study (ADA464771). Air Force Center for Systems Engineering, AFIT.",[],False,Which systems engineering practices most strongly correlate with achieving performance objectives while controlling cost/schedule in complex programs?,False,Which systems engineering practices most strongly correlate with achieving performance objectives while controlling cost/schedule in complex programs?,Which,DomainTopic=B-2 bomber development; systems engineering practices | ScenarioType=Acquisition program lifecycle (historical) | Hits=[],Which systems engineering practices most strongly correlate with achieving performance objectives while controlling cost/schedule in complex programs?,False
GLOBALHAWK-SE-CASE-2009,GLOBALHAWK-SE-CASE-2009-Q01,2009,AFIT / DTIC,Case Study (Technical Report),Global Hawk Systems Engineering Case Study (DTIC ADA538761),AF Center for Systems Engineering; Kinzig,Global Hawk UAV acquisition and SE lessons,Acquisition program lifecycle (historical),Retrospective case study; interviews; program documentation,Case study report; program history; requirements and test evolution,How should requirements and system architecture be evolved as operational demand and technology mature during a rapid fielding program?,Primary,Requirements evolution & architecture,Requirement; Capability; Architecture; Change; Stakeholder,Delivered ISR utility; mission availability,Requirement volatility; integration defect rates,Case study report (DTIC),High (full report openly available),Open (PDF via Internet Archive mirror),Public,Program management; ISR capability fielding,SE process case study,https://ia902805.us.archive.org/33/items/DTIC_ADA538761/DTIC_ADA538761.pdf,"Air Force Center for Systems Engineering & Kinzig, B. (2009). Global Hawk Systems Engineering Case Study (ADA538761). AFIT.",[],False,How should requirements and system architecture be evolved as operational demand and technology mature during a rapid fielding program?,False,How should requirements and system architecture be evolved as operational demand and technology mature during a rapid fielding program?,How,DomainTopic=Global Hawk UAV acquisition and SE lessons | ScenarioType=Acquisition program lifecycle (historical) | Hits=[],How should requirements and system architecture be evolved as operational demand and technology mature during a rapid fielding program?,False
GLOBALHAWK-SE-CASE-2009,GLOBALHAWK-SE-CASE-2009-Q02,2009,AFIT / DTIC,Case Study (Technical Report),Global Hawk Systems Engineering Case Study (DTIC ADA538761),AF Center for Systems Engineering; Kinzig,Global Hawk UAV acquisition and SE lessons,Acquisition program lifecycle (historical),Retrospective case study; interviews; program documentation,Case study report; program history; requirements and test evolution,"What verification, test, and operational feedback loops best support incremental capability delivery while maintaining airworthiness and mission performance?",Primary,"Test, evaluation & feedback",Test; Verification; Evidence; OperationalFeedback; Measure,Improved mission effectiveness with acceptable safety,Test coverage; defect discovery rate; sortie reliability,Case study report (DTIC),High (full report openly available),Open (PDF via Internet Archive mirror),Public,Program management; ISR capability fielding,SE process case study,https://ia902805.us.archive.org/33/items/DTIC_ADA538761/DTIC_ADA538761.pdf,"Air Force Center for Systems Engineering & Kinzig, B. (2009). Global Hawk Systems Engineering Case Study (ADA538761). AFIT.",[],False,"What verification, test, and operational feedback loops best support incremental capability delivery while maintaining airworthiness and mission performance?",False,"What verification, test, and operational feedback loops best support incremental capability delivery while maintaining airworthiness and mission performance?",What,DomainTopic=Global Hawk UAV acquisition and SE lessons | ScenarioType=Acquisition program lifecycle (historical) | Hits=[],"What verification, test, and operational feedback loops best support incremental capability delivery while maintaining airworthiness and mission performance?",False
CSER-2013-SoS-Dependency,CSER-2013-SoS-Dependency-Q01,2013,CSER / Procedia Computer Science,Conference Proceedings (Procedia),Dependency Analysis of System-of-Systems Operational and Development Networks,Guariniello; DeLaurentis,SoS operational and developmental dependency networks,Generic SoS dependency case with operational relevance,Operational/development dependency modeling; network analysis,Dependency network representations; metrics,What operational dependencies create single points of failure (or fragile cascades) that threaten mission success in a SoS?,Primary,Interdependencies & criticality,System; Interface; Dependency; Risk; Measure; Mission,Mission operability under failures,Critical node/link scores; cascade size,Method paper with illustrative examples,Medium (open proceedings PDF via ScienceDirect/ResearchGate),Open (PDF via ResearchGate),Public,Architecture risk; dependency management,Dependency network analysis,https://www.researchgate.net/profile/Cesare-Guariniello/publication/262758666_Dependency_Analysis_of_System-of-Systems_Operational_and_Development_Networks/links/5d9d5d5e92851c2f70f2e5b2/Dependency-Analysis-of-System-of-Systems-Operational-and-Development-Networks.pdf,"Guariniello, C., & DeLaurentis, D. (2013). Dependency Analysis of System-of-Systems Operational and Development Networks. Procedia Computer Science (CSER proceedings).",[],False,What operational dependencies create single points of failure (or fragile cascades) that threaten mission success in a SoS?,False,What operational dependencies create single points of failure (or fragile cascades) that threaten mission success in a SoS?,What,DomainTopic=SoS operational and developmental dependency networks | ScenarioType=Generic SoS dependency case with operational relevance | Hits=[],What operational dependencies create single points of failure (or fragile cascades) that threaten mission success in a SoS?,False
CSER-2013-SoS-Dependency,CSER-2013-SoS-Dependency-Q02,2013,CSER / Procedia Computer Science,Conference Proceedings (Procedia),Dependency Analysis of System-of-Systems Operational and Development Networks,Guariniello; DeLaurentis,SoS operational and developmental dependency networks,Generic SoS dependency case with operational relevance,Operational/development dependency modeling; network analysis,Dependency network representations; metrics,"Which development dependencies threaten timely delivery of integrated capability, and how should delivery sequencing be adjusted?",Primary,Schedule & developmental risk,Project; Schedule; Dependency; Capability; Risk,Time-to-field integrated capability,Delay propagation; dependency density,Method paper with illustrative examples,Medium (open proceedings PDF via ScienceDirect/ResearchGate),Open (PDF via ResearchGate),Public,Architecture risk; dependency management,Dependency network analysis,https://www.researchgate.net/profile/Cesare-Guariniello/publication/262758666_Dependency_Analysis_of_System-of-Systems_Operational_and_Development_Networks/links/5d9d5d5e92851c2f70f2e5b2/Dependency-Analysis-of-System-of-Systems-Operational-and-Development-Networks.pdf,"Guariniello, C., & DeLaurentis, D. (2013). Dependency Analysis of System-of-Systems Operational and Development Networks. Procedia Computer Science (CSER proceedings).",[],False,"Which development dependencies threaten timely delivery of integrated capability, and how should delivery sequencing be adjusted?",False,"Which development dependencies threaten timely delivery of integrated capability, and how should delivery sequencing be adjusted?",Which,DomainTopic=SoS operational and developmental dependency networks | ScenarioType=Generic SoS dependency case with operational relevance | Hits=[],"Which development dependencies threaten timely delivery of integrated capability, and how should delivery sequencing be adjusted?",False
CSER-2014-Ilities-Tradeoff,CSER-2014-Ilities-Tradeoff-Q01,2014,CSER / Procedia Computer Science,Conference Proceedings (Procedia),"Integrated Analysis of Functional and Developmental Interdependencies to Quantify and Trade-off Ilities for SoS Design, Architecture and Evolution",Guariniello; DeLaurentis,Trading ilities in SoS using integrated dependency analysis,SoS evolution / architecture selection,Integrated functional + developmental dependency analysis; ility quantification; trade-space analysis,Metrics; integrated dependency model; tradeoff examples,"How do different architecture choices change key ilities (resilience, flexibility, robustness) when both operational and developmental dependencies are considered?",Primary,Ilities trade-space,Architecture; Dependency; Ility; Risk; Measure; Tradeoff,Resilience/robustness of mission capability,Ility metrics derived from dependency structure,Method with illustrative examples,Medium (preprint PDF via ResearchGate),Open (PDF via ResearchGate),Public,Architecture selection & evolution planning,Integrated dependency + ility trade-space,https://www.researchgate.net/profile/Cesare-Guariniello/publication/280871209_Integrated_analysis_of_functional_and_developmental_interdependencies_to_quantify_and_trade-off_ilities_for_system-of-systems_design_architecture_and_evolution/links/55c90ca808ae09d975e7bdba/Integrated-analysis-of-functional-and-developmental-interdependencies-to-quantify-and-trade-off-ilities-for-system-of-systems-design-architecture-and-evolution.pdf,"Guariniello, C., & DeLaurentis, D. (2014). Integrated analysis of functional and developmental interdependencies to quantify and trade-off ilities for SoS design, architecture and evolution. Procedia Computer Science (CSER proceedings).",[],False,"How do different architecture choices change key ilities (resilience, flexibility, robustness) when both operational and developmental dependencies are considered?",False,"How do different architecture choices change key ilities (resilience, flexibility, robustness) when both operational and developmental dependencies are considered?",How,DomainTopic=Trading ilities in SoS using integrated dependency analysis | ScenarioType=SoS evolution / architecture selection | Hits=[],"How do different architecture choices change key ilities (resilience, flexibility, robustness) when both operational and developmental dependencies are considered?",False
CSER-2014-Ilities-Tradeoff,CSER-2014-Ilities-Tradeoff-Q02,2014,CSER / Procedia Computer Science,Conference Proceedings (Procedia),"Integrated Analysis of Functional and Developmental Interdependencies to Quantify and Trade-off Ilities for SoS Design, Architecture and Evolution",Guariniello; DeLaurentis,Trading ilities in SoS using integrated dependency analysis,SoS evolution / architecture selection,Integrated functional + developmental dependency analysis; ility quantification; trade-space analysis,Metrics; integrated dependency model; tradeoff examples,Which dependency-driven design changes yield the best improvement in selected ilities per unit cost/schedule impact?,Primary,Value of design changes,DesignChange; Dependency; Cost; Schedule; Measure; Tradeoff,Improved ility index; reduced mission risk,Cost/schedule delta; sensitivity,Method with illustrative examples,Medium (preprint PDF via ResearchGate),Open (PDF via ResearchGate),Public,Architecture selection & evolution planning,Integrated dependency + ility trade-space,https://www.researchgate.net/profile/Cesare-Guariniello/publication/280871209_Integrated_analysis_of_functional_and_developmental_interdependencies_to_quantify_and_trade-off_ilities_for_system-of-systems_design_architecture_and_evolution/links/55c90ca808ae09d975e7bdba/Integrated-analysis-of-functional-and-developmental-interdependencies-to-quantify-and-trade-off-ilities-for-system-of-systems-design-architecture-and-evolution.pdf,"Guariniello, C., & DeLaurentis, D. (2014). Integrated analysis of functional and developmental interdependencies to quantify and trade-off ilities for SoS design, architecture and evolution. Procedia Computer Science (CSER proceedings).",[],False,Which dependency-driven design changes yield the best improvement in selected ilities per unit cost/schedule impact?,False,Which dependency-driven design changes yield the best improvement in selected ilities per unit cost/schedule impact?,Which,DomainTopic=Trading ilities in SoS using integrated dependency analysis | ScenarioType=SoS evolution / architecture selection | Hits=[],Which dependency-driven design changes yield the best improvement in selected ilities per unit cost/schedule impact?,False
JDMS-2014-RoPARS,JDMS-2014-RoPARS-Q01,2014,Journal of Defense Modeling and Simulation (JDMS),Journal,Using robustness concepts to determine effective solutions for route planning and resource scheduling in village search,(As listed in paper PDF),Ground operations: village search route planning & resource scheduling,Tactical ground operation (search) with constraints,Robustness analysis; route planning; resource scheduling; scenario-based evaluation,Optimization/decision model; scenarios; solution sets,"Which route plans and resource schedules remain effective across uncertainty in threats, timing, and task durations (i.e., robust plans)?",Primary,Operational planning under uncertainty,OperationalActivity; Task; Resource; Constraint; Uncertainty; Measure,Search effectiveness; time-to-complete; mission success,Schedule slack; resource utilization; robustness score,Model-based analysis + scenario experimentation,Medium (preprint PDF available),Open (author PDF),Public,Operational planning,Optimization + robustness,https://engr.colostate.edu/~ash/papers/ropars.pdf,(Paper authors). (2014). Using robustness concepts to determine effective solutions for route planning and resource scheduling in village search. Journal of Defense Modeling and Simulation.,[],False,"Which route plans and resource schedules remain effective across uncertainty in threats, timing, and task durations (i.e., robust plans)?",False,"Which route plans and resource schedules remain effective across uncertainty in threats, timing, and task durations (i.e., robust plans)?",Which,DomainTopic=Ground operations: village search route planning & resource scheduling | ScenarioType=Tactical ground operation (search) with constraints | Hits=[],"Which route plans and resource schedules remain effective across uncertainty in threats, timing, and task durations (i.e., robust plans)?",False
JDMS-2014-RoPARS,JDMS-2014-RoPARS-Q02,2014,Journal of Defense Modeling and Simulation (JDMS),Journal,Using robustness concepts to determine effective solutions for route planning and resource scheduling in village search,(As listed in paper PDF),Ground operations: village search route planning & resource scheduling,Tactical ground operation (search) with constraints,Robustness analysis; route planning; resource scheduling; scenario-based evaluation,Optimization/decision model; scenarios; solution sets,"What are the tradeoffs between best-case optimality and robustness, and where should commanders accept performance degradation for plan stability?",Primary,Tradeoffs & decision robustness,Decision; Tradeoff; Measure; Uncertainty; Constraint,Stable performance across scenarios,Performance variance; regret; robustness margin,Model-based analysis + scenario experimentation,Medium (preprint PDF available),Open (author PDF),Public,Operational planning,Optimization + robustness,https://engr.colostate.edu/~ash/papers/ropars.pdf,(Paper authors). (2014). Using robustness concepts to determine effective solutions for route planning and resource scheduling in village search. Journal of Defense Modeling and Simulation.,[],False,"What are the tradeoffs between best-case optimality and robustness, and where should commanders accept performance degradation for plan stability?",False,"What are the tradeoffs between best-case optimality and robustness, and where should commanders accept performance degradation for plan stability?",What,DomainTopic=Ground operations: village search route planning & resource scheduling | ScenarioType=Tactical ground operation (search) with constraints | Hits=[],"What are the tradeoffs between best-case optimality and robustness, and where should commanders accept performance degradation for plan stability?",False
SERC-2017-TR-102,SERC-2017-TR-102-Q01,2017,SERC Technical Report,Technical Report,Assessing the Impact of Development Disruptions and Dependencies in System-of-Systems (SERC-2017-TR-102),DeLaurentis; Marais; Davendralingam; Guariniello; Fang; Chandrahasa,SoS developmental dependencies & disruption impacts,SoS evolution / acquisition schedules,SDDA; delay propagation; dependency analysis; SoS-AWB tool maturation,SoS-AWB methods overview; dependency/disruption analysis approach,Which developmental dependencies create the largest schedule-risk and mission-readiness impact if a subsystem slips or fails to deliver?,Primary,Schedule & developmental risk,Project; Schedule; Dependency; Risk; Capability; Measure,Readiness/capability availability date,Critical path length; delay propagation magnitude,Method + tool maturation report (with references to case usage),Medium,Open (PDF),Public,Program/portfolio scheduling; risk management,Developmental dependency network,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1526396224-SERC-2017-TR-102-Assessing-the-Impact-of-Development-Disruptions-and-Dependencies-in-System%E2%80%90of%E2%80%90Systems-102.pdf,"DeLaurentis, D., Marais, K., et al. (2017). Assessing the Impact of Development Disruptions and Dependencies in System-of-Systems (SERC-2017-TR-102). Systems Engineering Research Center.",[],False,Which developmental dependencies create the largest schedule-risk and mission-readiness impact if a subsystem slips or fails to deliver?,False,Which developmental dependencies create the largest schedule-risk and mission-readiness impact if a subsystem slips or fails to deliver?,Which,DomainTopic=SoS developmental dependencies & disruption impacts | ScenarioType=SoS evolution / acquisition schedules | Hits=[],Which developmental dependencies create the largest schedule-risk and mission-readiness impact if a subsystem slips or fails to deliver?,False
SERC-2017-TR-102,SERC-2017-TR-102-Q02,2017,SERC Technical Report,Technical Report,Assessing the Impact of Development Disruptions and Dependencies in System-of-Systems (SERC-2017-TR-102),DeLaurentis; Marais; Davendralingam; Guariniello; Fang; Chandrahasa,SoS developmental dependencies & disruption impacts,SoS evolution / acquisition schedules,SDDA; delay propagation; dependency analysis; SoS-AWB tool maturation,SoS-AWB methods overview; dependency/disruption analysis approach,"What mitigation actions (re-sequencing, decoupling, alternate suppliers/paths) reduce mission-level risk from development disruptions most effectively?",Primary,Risk mitigation & resilience,Mitigation; Dependency; Resource; Constraint; Risk; Measure,Reduced capability gap; improved robustness,Time-to-recover; dependency decoupling metrics,Method + tool maturation report (with references to case usage),Medium,Open (PDF),Public,Program/portfolio scheduling; risk management,Developmental dependency network,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1526396224-SERC-2017-TR-102-Assessing-the-Impact-of-Development-Disruptions-and-Dependencies-in-System%E2%80%90of%E2%80%90Systems-102.pdf,"DeLaurentis, D., Marais, K., et al. (2017). Assessing the Impact of Development Disruptions and Dependencies in System-of-Systems (SERC-2017-TR-102). Systems Engineering Research Center.",[],False,"What mitigation actions (re-sequencing, decoupling, alternate suppliers/paths) reduce mission-level risk from development disruptions most effectively?",False,"What mitigation actions (re-sequencing, decoupling, alternate suppliers/paths) reduce mission-level risk from development disruptions most effectively?",What,DomainTopic=SoS developmental dependencies & disruption impacts | ScenarioType=SoS evolution / acquisition schedules | Hits=[],"What mitigation actions (re-sequencing, decoupling, alternate suppliers/paths) reduce mission-level risk from development disruptions most effectively?",False
SERC-2017-TR-112,SERC-2017-TR-112-Q01,2017,SERC Technical Report,Technical Report,System of Systems Analytic Workbench – 2017 (SERC-2017-TR-112),Marais; DeLaurentis; Davendralingam; Guariniello; Fang; Chandrahasa,Naval Warfare Scenario (LCS-based) / SoS analytics toolset,Operational mission thread + SoS evolution,System Operational/Developmental Dependency Analysis (SODA/SDDA); Robust Portfolio Optimization (RPO); System Importance Measures (SIMs); Multi-stakeholder optimization; network/cut-set analysis,SoS Analytic Workbench (AWB) toolset; LCS-based case-study model; dependency networks; analysis scripts,"Which system nodes/links are most critical to mission capability delivery (i.e., what dependencies dominate mission failure modes)?",Primary,Interdependencies & criticality,OperationalActivity; Resource; System; Interface; Dependency; Risk; Measure,Mission capability/operability score; resilience/robustness,Dependency strength/criticality/impact; cut-set/path-set metrics,Tool demonstration + case-study walkthrough,Medium (methods and case described; full tool access not guaranteed via report alone),Open (PDF),Public,Architecture / portfolio selection; mission risk & resilience,SoS dependency network + optimization,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1526397206-A013_SERC-RT-178_Technical-Report-SERC-2017-TR-112.pdf,"Marais, K., DeLaurentis, D., Davendralingam, N., et al. (2017). System of Systems Analytic Workbench – 2017 (SERC-2017-TR-112). Systems Engineering Research Center.",[],False,"Which system nodes/links are most critical to mission capability delivery (i.e., what dependencies dominate mission failure modes)?",False,"Which system nodes/links are most critical to mission capability delivery (i.e., what dependencies dominate mission failure modes)?",Which,DomainTopic=Naval Warfare Scenario (LCS-based) / SoS analytics toolset | ScenarioType=Operational mission thread + SoS evolution | Hits=[],"Which system nodes/links are most critical to mission capability delivery (i.e., what dependencies dominate mission failure modes)?",False
SERC-2017-TR-112,SERC-2017-TR-112-Q02,2017,SERC Technical Report,Technical Report,System of Systems Analytic Workbench – 2017 (SERC-2017-TR-112),Marais; DeLaurentis; Davendralingam; Guariniello; Fang; Chandrahasa,Naval Warfare Scenario (LCS-based) / SoS analytics toolset,Operational mission thread + SoS evolution,System Operational/Developmental Dependency Analysis (SODA/SDDA); Robust Portfolio Optimization (RPO); System Importance Measures (SIMs); Multi-stakeholder optimization; network/cut-set analysis,SoS Analytic Workbench (AWB) toolset; LCS-based case-study model; dependency networks; analysis scripts,"Given a set of candidate systems and constraints, what portfolio or architecture mix is most robust to uncertainty and failure while meeting mission needs?",Primary,Portfolio/architecture trade-space,Capability; System; Resource; Constraint; Portfolio; Measure; Risk,Mission effectiveness; robustness under uncertainty,Cost; schedule; availability; dependency robustness,Tool demonstration + case-study walkthrough,Medium (methods and case described; full tool access not guaranteed via report alone),Open (PDF),Public,Architecture / portfolio selection; mission risk & resilience,SoS dependency network + optimization,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1526397206-A013_SERC-RT-178_Technical-Report-SERC-2017-TR-112.pdf,"Marais, K., DeLaurentis, D., Davendralingam, N., et al. (2017). System of Systems Analytic Workbench – 2017 (SERC-2017-TR-112). Systems Engineering Research Center.",[],False,"Given a set of candidate systems and constraints, what portfolio or architecture mix is most robust to uncertainty and failure while meeting mission needs?",False,"How should given a set of candidate systems and constraints, what portfolio or architecture mix is most robust to uncertainty and failure while meeting mission needs?",How,DomainTopic=Naval Warfare Scenario (LCS-based) / SoS analytics toolset | ScenarioType=Operational mission thread + SoS evolution | Hits=[],"Given a set of candidate systems and constraints, what portfolio or architecture mix is most robust to uncertainty and failure while meeting mission needs?",False
SERC-2017-TR-112,SERC-2017-TR-112-Q03,2017,SERC Technical Report,Technical Report,System of Systems Analytic Workbench – 2017 (SERC-2017-TR-112),Marais; DeLaurentis; Davendralingam; Guariniello; Fang; Chandrahasa,Naval Warfare Scenario (LCS-based) / SoS analytics toolset,Operational mission thread + SoS evolution,System Operational/Developmental Dependency Analysis (SODA/SDDA); Robust Portfolio Optimization (RPO); System Importance Measures (SIMs); Multi-stakeholder optimization; network/cut-set analysis,SoS Analytic Workbench (AWB) toolset; LCS-based case-study model; dependency networks; analysis scripts,How do technical or developmental disruptions propagate through a system-of-systems and what are the mission and schedule consequences over time?,Primary,"Evolution, disruption & resilience",Project; Schedule; Dependency; Risk; Capability; Measure,Mission readiness over time; capability gap duration,Delay propagation; developmental dependency metrics,Tool demonstration + case-study walkthrough,Medium (methods and case described; full tool access not guaranteed via report alone),Open (PDF),Public,Architecture / portfolio selection; mission risk & resilience,SoS dependency network + optimization,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1526397206-A013_SERC-RT-178_Technical-Report-SERC-2017-TR-112.pdf,"Marais, K., DeLaurentis, D., Davendralingam, N., et al. (2017). System of Systems Analytic Workbench – 2017 (SERC-2017-TR-112). Systems Engineering Research Center.",[],False,How do technical or developmental disruptions propagate through a system-of-systems and what are the mission and schedule consequences over time?,False,How do technical or developmental disruptions propagate through a system-of-systems and what are the mission and schedule consequences over time?,How,DomainTopic=Naval Warfare Scenario (LCS-based) / SoS analytics toolset | ScenarioType=Operational mission thread + SoS evolution | Hits=[],How do technical or developmental disruptions propagate through a system-of-systems and what are the mission and schedule consequences over time?,False
JDMS-2020-MCM-DES,JDMS-2020-MCM-DES-Q01,2020,Journal of Defense Modeling and Simulation (JDMS),Journal,An operational effectiveness analysis of legacy and future mine countermeasures systems using discrete event simulation,Beery; Byram; Gatley; Giammarco; Williams; Paulo,Naval mine countermeasures (legacy Avenger/MH-53E vs LCS + unmanned systems),Naval MCM operation (defensive mine countermeasures),Discrete Event Simulation; architectural representations (functional activities + physical entities); comparative analysis,DES model; architecture representations; performance drivers,How do alternative MCM force packages (legacy vs future unmanned-enabled) compare in operational effectiveness for representative mine warfare missions?,Primary,Alternative CONOPS/force package comparison,Mission; OperationalActivity; System; Resource; Measure; CONOPS,Area cleared; time-to-clear; mission completion probability,Sortie rate; sensor coverage; downtime; transit time,Simulation experiment + comparative case study,Medium (author PDF available; code/data not included),Open (author PDF via ResearchGate),Public,Force structure / capability transition,DES + architecture model,https://www.researchgate.net/profile/Paul-Beery/publication/331505928_An_operational_effectiveness_analysis_of_legacy_and_future_mine_countermeasures_systems_using_discrete_event_simulation/links/5e4c45de92851c7f7f456564/An-operational-effectiveness-analysis-of-legacy-and-future-mine-countermeasures-systems-using-discrete-event-simulation.pdf,"Beery, P., et al. (2020). An operational effectiveness analysis of legacy and future mine countermeasures systems using discrete event simulation. Journal of Defense Modeling and Simulation, 17(2), 191–204.","['MCM', 'mine']",True,How do alternative hazard clearance force packages (legacy vs future unmanned-enabled) compare in operational effectiveness for representative hazard clearance missions?,True,How do alternative hazard clearance force packages (legacy vs future unmanned-enabled) compare in operational effectiveness for representative hazard clearance missions?,How,"DomainTopic=Naval mine countermeasures (legacy Avenger/MH-53E vs LCS + unmanned systems) | ScenarioType=Naval MCM operation (defensive mine countermeasures) | Hits=['MCM', 'mine']",How do alternative MCM force packages (legacy vs future unmanned-enabled) compare in operational effectiveness for representative mine warfare missions?,False
JDMS-2020-MCM-DES,JDMS-2020-MCM-DES-Q02,2020,Journal of Defense Modeling and Simulation (JDMS),Journal,An operational effectiveness analysis of legacy and future mine countermeasures systems using discrete event simulation,Beery; Byram; Gatley; Giammarco; Williams; Paulo,Naval mine countermeasures (legacy Avenger/MH-53E vs LCS + unmanned systems),Naval MCM operation (defensive mine countermeasures),Discrete Event Simulation; architectural representations (functional activities + physical entities); comparative analysis,DES model; architecture representations; performance drivers,"What functional activities and system performance drivers most influence MCM mission outcomes, and where should investment focus to improve effectiveness?",Primary,"Drivers, bottlenecks & investment levers",Function; PerformanceParameter; System; Resource; Bottleneck; Measure,Improved mission throughput/effectiveness,Activity durations; reliability/availability; UxS capacity,Simulation experiment + comparative case study,Medium (author PDF available; code/data not included),Open (author PDF via ResearchGate),Public,Force structure / capability transition,DES + architecture model,https://www.researchgate.net/profile/Paul-Beery/publication/331505928_An_operational_effectiveness_analysis_of_legacy_and_future_mine_countermeasures_systems_using_discrete_event_simulation/links/5e4c45de92851c7f7f456564/An-operational-effectiveness-analysis-of-legacy-and-future-mine-countermeasures-systems-using-discrete-event-simulation.pdf,"Beery, P., et al. (2020). An operational effectiveness analysis of legacy and future mine countermeasures systems using discrete event simulation. Journal of Defense Modeling and Simulation, 17(2), 191–204.",['MCM'],True,"What functional activities and system performance drivers most influence hazard clearance mission outcomes, and where should investment focus to improve effectiveness?",True,"What functional activities and system performance drivers most influence hazard clearance mission outcomes, and where should investment focus to improve effectiveness?",What,DomainTopic=Naval mine countermeasures (legacy Avenger/MH-53E vs LCS + unmanned systems) | ScenarioType=Naval MCM operation (defensive mine countermeasures) | Hits=['MCM'],"What functional activities and system performance drivers most influence MCM mission outcomes, and where should investment focus to improve effectiveness?",False
NEJ-2020-MLA,NEJ-2020-MLA-Q01,2020,Naval Engineers Journal (ASNE),Journal,Mission-Level Assessment Case Studies: A Review of Recent Developments in Naval Mission Engineering,(as listed in journal),Naval mission-level assessment (MLA) case studies,Operationally realistic naval missions (various),Mission-level modeling; engineering assessment; case-study review,Case-study assessments; metrics; analysis frameworks,"Which mission-level measures best capture operational value for naval missions, and how should they be computed from model outputs?",Primary,Measures & assessment design,Measure; MoE; OperationalScenario; ModelOutput; Validation,Mission-level measures (varies by case),Model output metrics; mapping functions,Case study review / synthesis,Low-Medium (depends on underlying cases),Public (web page),Public,Mission assessment & modernization,Mission-level assessment frameworks,https://www.navalengineers.org/Pubsonline/NEJ/nej-archive/nej-sample-articles/mission-level-assessment-case-studies-a-review-of-recent-developments-in-naval-mission-engineering,Naval Engineers Journal. (2020). Mission-Level Assessment Case Studies: A Review of Recent Developments in Naval Mission Engineering.,[],False,"Which mission-level measures best capture operational value for naval missions, and how should they be computed from model outputs?",False,"Which mission-level measures best capture operational value for naval missions, and how should they be computed from model outputs?",Which,DomainTopic=Naval mission-level assessment (MLA) case studies | ScenarioType=Operationally realistic naval missions (various) | Hits=[],"Which mission-level measures best capture operational value for naval missions, and how should they be computed from model outputs?",False
NEJ-2020-MLA,NEJ-2020-MLA-Q02,2020,Naval Engineers Journal (ASNE),Journal,Mission-Level Assessment Case Studies: A Review of Recent Developments in Naval Mission Engineering,(as listed in journal),Naval mission-level assessment (MLA) case studies,Operationally realistic naval missions (various),Mission-level modeling; engineering assessment; case-study review,Case-study assessments; metrics; analysis frameworks,"Across recent naval mission engineering assessments, what modeling approaches and abstractions provide decision-useful fidelity without overbuilding models?",Primary,Modeling approach & fidelity,Model; Abstraction; Fidelity; Assumption; Evidence,Decision usefulness; credibility,Model complexity; run time; data demands,Case study review / synthesis,Low-Medium (depends on underlying cases),Public (web page),Public,Mission assessment & modernization,Mission-level assessment frameworks,https://www.navalengineers.org/Pubsonline/NEJ/nej-archive/nej-sample-articles/mission-level-assessment-case-studies-a-review-of-recent-developments-in-naval-mission-engineering,Naval Engineers Journal. (2020). Mission-Level Assessment Case Studies: A Review of Recent Developments in Naval Mission Engineering.,[],False,"Across recent naval mission engineering assessments, what modeling approaches and abstractions provide decision-useful fidelity without overbuilding models?",False,"How should across recent naval mission engineering assessments, what modeling approaches and abstractions provide decision-useful fidelity without overbuilding models?",How,DomainTopic=Naval mission-level assessment (MLA) case studies | ScenarioType=Operationally realistic naval missions (various) | Hits=[],"Across recent naval mission engineering assessments, what modeling approaches and abstractions provide decision-useful fidelity without overbuilding models?",False
RAND-2020-DKC,RAND-2020-DKC-Q01,2020,RAND Corporation,Research Report,Distributed Kill Chains: Drawing Insights from the Falklands War,Posen; et al. (RAND),Distributed kill chains / operational learning (Falklands),Historical operational campaign analysis,Historical analysis; conceptual modeling of kill chains,Report narrative; inferred kill-chain structures,What organizational and technical enabling factors allow kill-chain functions to be distributed yet remain effective under contested conditions?,Primary,Mission thread orchestration,MissionThread; Function; System; Organization; Interface; Constraint,Kill-chain completion rate; time-to-engage,Coordination latency; comms reliability; sensor-to-shooter handoff,Historical case study,Medium (open report),Open,Public,Operational concepts & force design,Kill-chain conceptual model,https://www.rand.org/pubs/research_reports/RR3051.html,RAND Corporation. (2020). Distributed Kill Chains: Drawing Insights from the Falklands War (RR-3051).,[],False,What organizational and technical enabling factors allow kill-chain functions to be distributed yet remain effective under contested conditions?,False,What organizational and technical enabling factors allow kill-chain functions to be distributed yet remain effective under contested conditions?,What,DomainTopic=Distributed kill chains / operational learning (Falklands) | ScenarioType=Historical operational campaign analysis | Hits=[],What organizational and technical enabling factors allow kill-chain functions to be distributed yet remain effective under contested conditions?,False
RAND-2020-DKC,RAND-2020-DKC-Q02,2020,RAND Corporation,Research Report,Distributed Kill Chains: Drawing Insights from the Falklands War,Posen; et al. (RAND),Distributed kill chains / operational learning (Falklands),Historical operational campaign analysis,Historical analysis; conceptual modeling of kill chains,Report narrative; inferred kill-chain structures,"What vulnerabilities emerge when kill-chain elements are distributed (e.g., comms dependence), and how can resilience be designed into the mission thread?",Primary,Mission assurance & resilience,Threat; Vulnerability; Dependency; Risk; Mitigation; Measure,Sustained kill-chain effectiveness under attack,Alternate paths; redundancy; degradation curves,Historical case study,Medium (open report),Open,Public,Operational concepts & force design,Kill-chain conceptual model,https://www.rand.org/pubs/research_reports/RR3051.html,RAND Corporation. (2020). Distributed Kill Chains: Drawing Insights from the Falklands War (RR-3051).,[],False,"What vulnerabilities emerge when kill-chain elements are distributed (e.g., comms dependence), and how can resilience be designed into the mission thread?",False,"What vulnerabilities emerge when kill-chain elements are distributed (e.g., comms dependence), and how can resilience be designed into the mission thread?",What,DomainTopic=Distributed kill chains / operational learning (Falklands) | ScenarioType=Historical operational campaign analysis | Hits=[],"What vulnerabilities emerge when kill-chain elements are distributed (e.g., comms dependence), and how can resilience be designed into the mission thread?",False
JHUAPL-2021-AMD-SoS,JHUAPL-2021-AMD-SoS-Q01,2021,JHU/APL Technical Publication,Journal/Tech Publication,A System-of-Systems Engineering Approach to Air Missile Defense,Beard; Chiu; Durazzo,Air and Missile Defense (AMD) SoS engineering,Operational air/missile defense SoS,SoS engineering; architecture/analysis; mission effects,Article; conceptual framework; likely model-based evaluations,"How should AMD capabilities be architected and integrated (sensors, C2, shooters) to achieve desired defended-asset outcomes across evolving threats?",Primary,Architecture & integration for mission effects,Capability; System; Interface; InformationFlow; Threat; Measure,Probability of raid annihilation; defended asset survival,Latency; track quality; interceptor inventory,Applied approach description + examples,Low-Medium,Open (PDF),Public,SoS architecture & CONOPS,SoS architecture + analysis,https://www.jhuapl.edu/Content/techdigest/pdf/V30-N01/30-01-Beard.pdf,"Beard, J., Chiu, S., & Durazzo, D. (2011). A System-of-Systems Engineering Approach to Air Missile Defense. Johns Hopkins APL Technical Digest, 30(1).","['AMD', 'sensors', 'C2', 'shooters']",True,"How should defense capabilities be architected and integrated (sensing assets, command and control, effectors) to achieve desired defended-asset outcomes across evolving threats?",True,"How should defense capabilities be architected and integrated (sensing assets, command and control, effectors) to achieve desired defended-asset outcomes across evolving threats?",How,"DomainTopic=Air and Missile Defense (AMD) SoS engineering | ScenarioType=Operational air/missile defense SoS | Hits=['AMD', 'sensors', 'C2', 'shooters']","How should AMD capabilities be architected and integrated (sensors, C2, shooters) to achieve desired defended-asset outcomes across evolving threats?",False
JHUAPL-2021-AMD-SoS,JHUAPL-2021-AMD-SoS-Q02,2021,JHU/APL Technical Publication,Journal/Tech Publication,A System-of-Systems Engineering Approach to Air Missile Defense,Beard; Chiu; Durazzo,Air and Missile Defense (AMD) SoS engineering,Operational air/missile defense SoS,SoS engineering; architecture/analysis; mission effects,Article; conceptual framework; likely model-based evaluations,"Which SoS-level performance drivers and interoperability constraints most limit AMD mission effectiveness, and what upgrades provide the best leverage?",Primary,Drivers & upgrade levers,Constraint; Interoperability; PerformanceParameter; Upgrade; Measure,Improved defended asset outcomes,Interoperability maturity; engagement timeline margins,Applied approach description + examples,Low-Medium,Open (PDF),Public,SoS architecture & CONOPS,SoS architecture + analysis,https://www.jhuapl.edu/Content/techdigest/pdf/V30-N01/30-01-Beard.pdf,"Beard, J., Chiu, S., & Durazzo, D. (2011). A System-of-Systems Engineering Approach to Air Missile Defense. Johns Hopkins APL Technical Digest, 30(1).",['AMD'],True,"Which SoS-level performance drivers and interoperability constraints most limit defense mission effectiveness, and what upgrades provide the best leverage?",True,"Which SoS-level performance drivers and interoperability constraints most limit defense mission effectiveness, and what upgrades provide the best leverage?",Which,DomainTopic=Air and Missile Defense (AMD) SoS engineering | ScenarioType=Operational air/missile defense SoS | Hits=['AMD'],"Which SoS-level performance drivers and interoperability constraints most limit AMD mission effectiveness, and what upgrades provide the best leverage?",False
AIRC-2022-REPORT-1049.5,AIRC-2022-REPORT-1049.5-Q01,2022,AIRC Report,Technical Report,Report on Data-Driven Capability Portfolio Management Pilot (WRT-1049.5),AIRC research team (Purdue/GTRI/Stevens/Virginia Tech et al.),Integrated Acquisition Portfolio Reviews (IAPR); Anti-Surface Warfare (ASuW) mission thread,Operational mission thread + acquisition portfolio decision support,SoS-AWB; mission engineering analysis; Robust Portfolio Optimization; Discrete Event Simulation; cost-sensitivity analysis,Prototype decision-support software; ASuW mission-thread model; RPO routines; DES scenario models,"For a specific mission thread (ASuW), what mix/quantity of systems provides the best mission performance under cost, schedule, and risk constraints?",Primary,Portfolio/architecture trade-space,MissionThread; Capability; System; Resource; Constraint; Portfolio; Measure; Risk,Mission success probability; time-to-effect; target servicing,Cost; inventory/munitions; sortie rates; schedule,"Prototype demonstration (Sept 8, 2022) + analytics results",Medium (report describes approach; software availability unclear),Open (PDF),Public,Capability portfolio management / IAPR,Mission thread + DES + portfolio optimization,https://document.acqirc.org/publication_documents/reports/1667588895.1049.5_REPORT.pdf,Acquisition Innovation Research Center. (2022). Report on Data-Driven Capability Portfolio Management Pilot (WRT-1049.5).,['ASuW'],True,"For a specific mission thread (surface engagement), what mix/quantity of systems provides the best mission performance under cost, schedule, and risk constraints?",True,"For a specific mission thread (surface engagement), what mix/quantity of systems provides the best mission performance under cost, schedule, and risk constraints?",How,DomainTopic=Integrated Acquisition Portfolio Reviews (IAPR); Anti-Surface Warfare (ASuW) mission thread | ScenarioType=Operational mission thread + acquisition portfolio decision support | Hits=['ASuW'],"For a specific mission thread (ASuW), what mix/quantity of systems provides the best mission performance under cost, schedule, and risk constraints?",False
AIRC-2022-REPORT-1049.5,AIRC-2022-REPORT-1049.5-Q02,2022,AIRC Report,Technical Report,Report on Data-Driven Capability Portfolio Management Pilot (WRT-1049.5),AIRC research team (Purdue/GTRI/Stevens/Virginia Tech et al.),Integrated Acquisition Portfolio Reviews (IAPR); Anti-Surface Warfare (ASuW) mission thread,Operational mission thread + acquisition portfolio decision support,SoS-AWB; mission engineering analysis; Robust Portfolio Optimization; Discrete Event Simulation; cost-sensitivity analysis,Prototype decision-support software; ASuW mission-thread model; RPO routines; DES scenario models,"Which resources and tradeoffs (personnel, munitions, platform availability) are the dominant drivers of mission effectiveness and portfolio robustness?",Primary,Resource tradeoffs & drivers,Resource; System; OperationalActivity; Measure; Sensitivity,Mission throughput; coverage; effectiveness,Resource utilization; sensitivity/elasticity to cost and inventory,"Prototype demonstration (Sept 8, 2022) + analytics results",Medium (report describes approach; software availability unclear),Open (PDF),Public,Capability portfolio management / IAPR,Mission thread + DES + portfolio optimization,https://document.acqirc.org/publication_documents/reports/1667588895.1049.5_REPORT.pdf,Acquisition Innovation Research Center. (2022). Report on Data-Driven Capability Portfolio Management Pilot (WRT-1049.5).,[],False,"Which resources and tradeoffs (personnel, munitions, platform availability) are the dominant drivers of mission effectiveness and portfolio robustness?",False,"Which resources and tradeoffs (personnel, munitions, platform availability) are the dominant drivers of mission effectiveness and portfolio robustness?",Which,DomainTopic=Integrated Acquisition Portfolio Reviews (IAPR); Anti-Surface Warfare (ASuW) mission thread | ScenarioType=Operational mission thread + acquisition portfolio decision support | Hits=[],"Which resources and tradeoffs (personnel, munitions, platform availability) are the dominant drivers of mission effectiveness and portfolio robustness?",False
AIRC-2022-REPORT-1049.5,AIRC-2022-REPORT-1049.5-Q03,2022,AIRC Report,Technical Report,Report on Data-Driven Capability Portfolio Management Pilot (WRT-1049.5),AIRC research team (Purdue/GTRI/Stevens/Virginia Tech et al.),Integrated Acquisition Portfolio Reviews (IAPR); Anti-Surface Warfare (ASuW) mission thread,Operational mission thread + acquisition portfolio decision support,SoS-AWB; mission engineering analysis; Robust Portfolio Optimization; Discrete Event Simulation; cost-sensitivity analysis,Prototype decision-support software; ASuW mission-thread model; RPO routines; DES scenario models,"How sensitive are portfolio decisions to assumptions (risk aversion, dependency structure, technology injects) and where are the biggest decision cliffs?",Primary,"Uncertainty, sensitivity & decision robustness",Assumption; Uncertainty; Risk; Dependency; Portfolio; Measure,Robust mission performance across uncertainties,RPO robustness metrics; scenario variance,"Prototype demonstration (Sept 8, 2022) + analytics results",Medium (report describes approach; software availability unclear),Open (PDF),Public,Capability portfolio management / IAPR,Mission thread + DES + portfolio optimization,https://document.acqirc.org/publication_documents/reports/1667588895.1049.5_REPORT.pdf,Acquisition Innovation Research Center. (2022). Report on Data-Driven Capability Portfolio Management Pilot (WRT-1049.5).,[],False,"How sensitive are portfolio decisions to assumptions (risk aversion, dependency structure, technology injects) and where are the biggest decision cliffs?",False,"How sensitive are portfolio decisions to assumptions (risk aversion, dependency structure, technology injects) and where are the biggest decision cliffs?",How,DomainTopic=Integrated Acquisition Portfolio Reviews (IAPR); Anti-Surface Warfare (ASuW) mission thread | ScenarioType=Operational mission thread + acquisition portfolio decision support | Hits=[],"How sensitive are portfolio decisions to assumptions (risk aversion, dependency structure, technology injects) and where are the biggest decision cliffs?",False
AIRC-2022-TR-007,AIRC-2022-TR-007-Q01,2022,AIRC Report,Technical Report,Interoperable and Integrated Capabilities for Mission Effects (AIRC-2022-TR-007),DeLaurentis (speaker) / AIRC task team,Electronic Warfare portfolio insights; interoperability/integration for mission effects,Portfolio + mission effects (EW context),Digital engineering models; portfolio-centric analysis; capability interactions,Report and briefing; concept of operations for IAPR decision-support,"Which interoperability gaps most limit mission effects, and what integrations yield the largest mission-level payoff per unit investment?",Primary,Interoperability & integration,Interface; InformationExchange; System; Capability; Constraint; Measure,Mission effects achieved; EW effectiveness,Interoperability maturity; integration cost/time,Demonstration-focused report/brief,Low-Medium,Open (PDF),Public,Portfolio integration & interoperability planning,Portfolio analytics + digital engineering models,https://document.acqirc.org/publication_documents/reports/1670509965.ARR-22-AIRC-Interoperable%20and%20Integrated%20Capabilities%20for%20Mission%20Effects.pdf,Acquisition Innovation Research Center. (2022). Interoperable and Integrated Capabilities for Mission Effects (AIRC-2022-TR-007).,[],False,"Which interoperability gaps most limit mission effects, and what integrations yield the largest mission-level payoff per unit investment?",False,"Which interoperability gaps most limit mission effects, and what integrations yield the largest mission-level payoff per unit investment?",Which,DomainTopic=Electronic Warfare portfolio insights; interoperability/integration for mission effects | ScenarioType=Portfolio + mission effects (EW context) | Hits=[],"Which interoperability gaps most limit mission effects, and what integrations yield the largest mission-level payoff per unit investment?",False
AIRC-2022-TR-007,AIRC-2022-TR-007-Q02,2022,AIRC Report,Technical Report,Interoperable and Integrated Capabilities for Mission Effects (AIRC-2022-TR-007),DeLaurentis (speaker) / AIRC task team,Electronic Warfare portfolio insights; interoperability/integration for mission effects,Portfolio + mission effects (EW context),Digital engineering models; portfolio-centric analysis; capability interactions,Report and briefing; concept of operations for IAPR decision-support,How should acquisition portfolios be organized and reviewed to expose cross-program interactions that materially change mission outcomes?,Primary,Portfolio governance & review questions,Portfolio; Stakeholder; Decision; Governance; Measure,Improved decision quality; reduced unintended interactions,Review cadence; traceability to mission threads,Demonstration-focused report/brief,Low-Medium,Open (PDF),Public,Portfolio integration & interoperability planning,Portfolio analytics + digital engineering models,https://document.acqirc.org/publication_documents/reports/1670509965.ARR-22-AIRC-Interoperable%20and%20Integrated%20Capabilities%20for%20Mission%20Effects.pdf,Acquisition Innovation Research Center. (2022). Interoperable and Integrated Capabilities for Mission Effects (AIRC-2022-TR-007).,[],False,How should acquisition portfolios be organized and reviewed to expose cross-program interactions that materially change mission outcomes?,False,How should acquisition portfolios be organized and reviewed to expose cross-program interactions that materially change mission outcomes?,How,DomainTopic=Electronic Warfare portfolio insights; interoperability/integration for mission effects | ScenarioType=Portfolio + mission effects (EW context) | Hits=[],How should acquisition portfolios be organized and reviewed to expose cross-program interactions that materially change mission outcomes?,False
NPS-2023-ME-AWB,NPS-2023-ME-AWB-Q01,2023,NPS Symposium (Proceedings/Paper),Conference/Proceedings,A Mission Engineering Approach to Informing U.S. Navy Decision-Making in Multi-Domain Operations,Khaw; MacKinnon; Thomas; DeLaurentis,U.S. Navy decision-making for multi-domain operations,Operationally realistic Navy mission thread(s),Mission engineering framing; SoS-AWB analytics; multi-domain modeling,Paper; conceptual workflow; (likely) models and analysis results,"In a contested multi-domain operational context, which cross-domain capability combinations produce the required mission effects at acceptable risk?",Primary,Multi-domain mission effectiveness,Mission; MissionThread; Capability; System; Environment; Threat; Risk; Measure,Effects achieved; mission success; survivability,Coverage; latency; attrition; resource expenditure,Case-study methodology + example application,Medium,Open (PDF),Public,Operational planning + capability modernization,Mission threads + analytics/optimization,https://nps.edu/documents/113838019/115126059/NPS+Symposium+Proceedings+Paper+Mission+Engineering+Approach.pdf,"Khaw, D., MacKinnon, E., Thomas, G., & DeLaurentis, D. (2023). A Mission Engineering Approach to Informing U.S. Navy Decision-Making in Multi-Domain Operations. Naval Postgraduate School.",[],False,"In a contested multi-domain operational context, which cross-domain capability combinations produce the required mission effects at acceptable risk?",False,"In a contested multi-domain operational context, which cross-domain capability combinations produce the required mission effects at acceptable risk?",How,DomainTopic=U.S. Navy decision-making for multi-domain operations | ScenarioType=Operationally realistic Navy mission thread(s) | Hits=[],"In a contested multi-domain operational context, which cross-domain capability combinations produce the required mission effects at acceptable risk?",False
NPS-2023-ME-AWB,NPS-2023-ME-AWB-Q02,2023,NPS Symposium (Proceedings/Paper),Conference/Proceedings,A Mission Engineering Approach to Informing U.S. Navy Decision-Making in Multi-Domain Operations,Khaw; MacKinnon; Thomas; DeLaurentis,U.S. Navy decision-making for multi-domain operations,Operationally realistic Navy mission thread(s),Mission engineering framing; SoS-AWB analytics; multi-domain modeling,Paper; conceptual workflow; (likely) models and analysis results,"Where are the highest-leverage changes (tactics, integrations, or acquisitions) to close mission gaps revealed by mission-engineering analysis?",Primary,Gap analysis & modernization options,Gap; Requirement; Capability; Integration; Portfolio; Measure,Gap closure magnitude; time-to-close,Integration effort; cost/schedule,Case-study methodology + example application,Medium,Open (PDF),Public,Operational planning + capability modernization,Mission threads + analytics/optimization,https://nps.edu/documents/113838019/115126059/NPS+Symposium+Proceedings+Paper+Mission+Engineering+Approach.pdf,"Khaw, D., MacKinnon, E., Thomas, G., & DeLaurentis, D. (2023). A Mission Engineering Approach to Informing U.S. Navy Decision-Making in Multi-Domain Operations. Naval Postgraduate School.",[],False,"Where are the highest-leverage changes (tactics, integrations, or acquisitions) to close mission gaps revealed by mission-engineering analysis?",False,"Where are the highest-leverage changes (tactics, integrations, or acquisitions) to close mission gaps revealed by mission-engineering analysis?",Where,DomainTopic=U.S. Navy decision-making for multi-domain operations | ScenarioType=Operationally realistic Navy mission thread(s) | Hits=[],"Where are the highest-leverage changes (tactics, integrations, or acquisitions) to close mission gaps revealed by mission-engineering analysis?",False
MDPI-2024-CUAS-KC,MDPI-2024-CUAS-KC-Q01,2024,MDPI (Aerospace / Sensors or similar),Journal,Mission Engineering to Improve Counter-Unmanned Aircraft System Capabilities: A Kill Chain Analysis,(as listed in paper),Counter-UAS mission engineering via kill-chain analysis,Operational CUAS mission thread,Kill-chain analysis; mission engineering; possibly MBSE/analysis framework,Paper; kill-chain model; recommendations,"Where are the weakest links (detection, tracking, identification, engagement, assessment) in the CUAS kill chain, and which improvements yield the largest mission-effect gains?",Primary,Kill-chain bottlenecks & improvements,MissionThread; Function; System; PerformanceParameter; Gap; Measure,Probability of interdiction; time-to-intercept,Detection range; track continuity; engagement latency,Analytic case study,Medium (open-access paper),Open (PDF),Public,Operational capability improvement,Kill-chain model/analysis,https://www.mdpi.com/2226-4310/11/4/242,(Authors). (2024). Mission Engineering to Improve Counter-Unmanned Aircraft System Capabilities: A Kill Chain Analysis. MDPI.,['CUAS'],True,"Where are the weakest links (detection, tracking, identification, engagement, assessment) in the counter-intrusion kill chain, and which improvements yield the largest mission-effect gains?",True,"Where are the weakest links (detection, tracking, identification, engagement, assessment) in the counter-intrusion kill chain, and which improvements yield the largest mission-effect gains?",Where,DomainTopic=Counter-UAS mission engineering via kill-chain analysis | ScenarioType=Operational CUAS mission thread | Hits=['CUAS'],"Where are the weakest links (detection, tracking, identification, engagement, assessment) in the CUAS kill chain, and which improvements yield the largest mission-effect gains?",False
MDPI-2024-CUAS-KC,MDPI-2024-CUAS-KC-Q02,2024,MDPI (Aerospace / Sensors or similar),Journal,Mission Engineering to Improve Counter-Unmanned Aircraft System Capabilities: A Kill Chain Analysis,(as listed in paper),Counter-UAS mission engineering via kill-chain analysis,Operational CUAS mission thread,Kill-chain analysis; mission engineering; possibly MBSE/analysis framework,Paper; kill-chain model; recommendations,How do different CUAS architectural choices and CONOPS affect end-to-end kill-chain performance under realistic threat variations?,Primary,Architecture/CONOPS comparison,CONOPS; Architecture; Threat; Scenario; Measure; Tradeoff,End-to-end interdiction effectiveness,Resource expenditure; false alarm rate; coverage,Analytic case study,Medium (open-access paper),Open (PDF),Public,Operational capability improvement,Kill-chain model/analysis,https://www.mdpi.com/2226-4310/11/4/242,(Authors). (2024). Mission Engineering to Improve Counter-Unmanned Aircraft System Capabilities: A Kill Chain Analysis. MDPI.,['CUAS'],True,How do different counter-intrusion architectural choices and CONOPS affect end-to-end kill-chain performance under realistic threat variations?,True,How do different counter-intrusion architectural choices and CONOPS affect end-to-end kill-chain performance under realistic threat variations?,How,DomainTopic=Counter-UAS mission engineering via kill-chain analysis | ScenarioType=Operational CUAS mission thread | Hits=['CUAS'],How do different CUAS architectural choices and CONOPS affect end-to-end kill-chain performance under realistic threat variations?,True
NDIA-2024-DAHMANN,NDIA-2024-DAHMANN-Q01,2024,NDIA Systems & Mission Engineering Conference,Conference Slides,Through Life Perspectives in Mission Engineering,Dahmann,Mission engineering across lifecycle and sustainment/evolution,Lifecycle mission engineering perspective (with examples),Lifecycle framing; mission engineering patterns,Slides,"How do mission needs, threats, and system capabilities co-evolve over time, and what lifecycle decisions preserve mission effectiveness?",Primary,Evolution & lifecycle decision-making,Lifecycle; Threat; Environment; Capability; Risk; Measure,Sustained mission effectiveness across time,Upgrade cadence; sustainment readiness,Conceptual + experiential briefing,Low,Open (slides),Public,Lifecycle decisions; sustainment; modernization,Lifecycle mission engineering concepts,https://ndiastorage.blob.core.usgovcloudapi.net/ndia/2024/SME/Tuesday/2B/2B-03_Dahmann.pdf,"Dahmann, J. (2024). Through Life Perspectives in Mission Engineering. NDIA Systems & Mission Engineering Conference.",[],False,"How do mission needs, threats, and system capabilities co-evolve over time, and what lifecycle decisions preserve mission effectiveness?",False,"How do mission needs, threats, and system capabilities co-evolve over time, and what lifecycle decisions preserve mission effectiveness?",How,DomainTopic=Mission engineering across lifecycle and sustainment/evolution | ScenarioType=Lifecycle mission engineering perspective (with examples) | Hits=[],"How do mission needs, threats, and system capabilities co-evolve over time, and what lifecycle decisions preserve mission effectiveness?",False
NDIA-2024-DAHMANN,NDIA-2024-DAHMANN-Q02,2024,NDIA Systems & Mission Engineering Conference,Conference Slides,Through Life Perspectives in Mission Engineering,Dahmann,Mission engineering across lifecycle and sustainment/evolution,Lifecycle mission engineering perspective (with examples),Lifecycle framing; mission engineering patterns,Slides,Where should mission engineering focus to anticipate emergent interactions and avoid lifecycle surprises in acknowledged systems-of-systems?,Primary,Emergence & lifecycle risk,Emergence; Dependency; Risk; Interface; Measure,Reduced surprise failures; resilience,Monitoring indicators; dependency change rates,Conceptual + experiential briefing,Low,Open (slides),Public,Lifecycle decisions; sustainment; modernization,Lifecycle mission engineering concepts,https://ndiastorage.blob.core.usgovcloudapi.net/ndia/2024/SME/Tuesday/2B/2B-03_Dahmann.pdf,"Dahmann, J. (2024). Through Life Perspectives in Mission Engineering. NDIA Systems & Mission Engineering Conference.",[],False,Where should mission engineering focus to anticipate emergent interactions and avoid lifecycle surprises in acknowledged systems-of-systems?,False,Where should mission engineering focus to anticipate emergent interactions and avoid lifecycle surprises in acknowledged systems-of-systems?,Where,DomainTopic=Mission engineering across lifecycle and sustainment/evolution | ScenarioType=Lifecycle mission engineering perspective (with examples) | Hits=[],Where should mission engineering focus to anticipate emergent interactions and avoid lifecycle surprises in acknowledged systems-of-systems?,False
NDIA-2024-GOLDENBERG,NDIA-2024-GOLDENBERG-Q01,2024,NDIA Systems & Mission Engineering Conference,Conference Paper/Slides,A Reusable Digital Engineering Environment to Support Mission Engineering Studies,Goldenberg (Payson Consulting) et al.,Reusable digital engineering environments for mission engineering,Digital environment demonstration (generalizable),Digital engineering environment integration; model reuse; study workflows,Paper PDF / environment concept,What model assets should be standardized/reused to reduce cycle time and improve consistency across mission engineering studies?,Primary,Infrastructure & model reuse,ModelAsset; Repository; Standard; Traceability; Configuration,Reduced study cycle time; improved consistency,Reuse rate; integration effort,Concept + example(s) of environment use,Low-Medium,Open (PDF),Public,Toolchain/infrastructure for mission engineering,Digital engineering environment,https://payson-consulting.com/wp-content/uploads/2024/04/Reusable-DE-Environment-to-Support-Mission-Engineering-Studies_Goldenberg.pdf,"Goldenberg, M. (2024). A Reusable Digital Engineering Environment to Support Mission Engineering Studies. NDIA Systems & Mission Engineering Conference.",[],False,What model assets should be standardized/reused to reduce cycle time and improve consistency across mission engineering studies?,False,What model assets should be standardized/reused to reduce cycle time and improve consistency across mission engineering studies?,What,DomainTopic=Reusable digital engineering environments for mission engineering | ScenarioType=Digital environment demonstration (generalizable) | Hits=[],What model assets should be standardized/reused to reduce cycle time and improve consistency across mission engineering studies?,False
NDIA-2024-GOLDENBERG,NDIA-2024-GOLDENBERG-Q02,2024,NDIA Systems & Mission Engineering Conference,Conference Paper/Slides,A Reusable Digital Engineering Environment to Support Mission Engineering Studies,Goldenberg (Payson Consulting) et al.,Reusable digital engineering environments for mission engineering,Digital environment demonstration (generalizable),Digital engineering environment integration; model reuse; study workflows,Paper PDF / environment concept,"How can digital engineering environments support end-to-end traceability from mission questions to models, experiments, and evidence?",Primary,Traceability & evidence management,Traceability; Evidence; Experiment; Requirement; Measure,Auditability/defensibility of conclusions,Coverage of trace links; reproducibility score,Concept + example(s) of environment use,Low-Medium,Open (PDF),Public,Toolchain/infrastructure for mission engineering,Digital engineering environment,https://payson-consulting.com/wp-content/uploads/2024/04/Reusable-DE-Environment-to-Support-Mission-Engineering-Studies_Goldenberg.pdf,"Goldenberg, M. (2024). A Reusable Digital Engineering Environment to Support Mission Engineering Studies. NDIA Systems & Mission Engineering Conference.",[],False,"How can digital engineering environments support end-to-end traceability from mission questions to models, experiments, and evidence?",False,"How can digital engineering environments support end-to-end traceability from mission questions to models, experiments, and evidence?",How,DomainTopic=Reusable digital engineering environments for mission engineering | ScenarioType=Digital environment demonstration (generalizable) | Hits=[],"How can digital engineering environments support end-to-end traceability from mission questions to models, experiments, and evidence?",False
NDIA-2024-PENNOCK,NDIA-2024-PENNOCK-Q01,2024,NDIA Systems & Mission Engineering Conference,Conference Slides,Leveraging Architecture to Inform the Design of Simulation Experiments for Mission Engineering Studies,Pennock; McMullen (MITRE),Mission engineering study design; simulation experiments informed by architecture,Mission engineering study pattern (generalizable) + example(s),Architecture-driven experiment design; linking architectural models to simulation,Slides; workflow; experiment design guidance,What architectural elements and assumptions must be captured to design simulation experiments that answer mission-level questions credibly?,Primary,Study design & validity,Architecture; Assumption; Scenario; Measure; Validation; Traceability,Credible mission-level insight,Coverage of assumptions; sensitivity plan,Methodology presentation with examples,Low-Medium,Open (slides),Public,Study design / analysis planning,Architecture-to-simulation linkage,https://ndiastorage.blob.core.usgovcloudapi.net/ndia/2024/SME/Tuesday/2B/2B-01_Pennock_McMullen.pdf,"Pennock, M., & McMullen, J. (2024). Leveraging Architecture to Inform the Design of Simulation Experiments for Mission Engineering Studies. NDIA Systems & Mission Engineering Conference.",[],False,What architectural elements and assumptions must be captured to design simulation experiments that answer mission-level questions credibly?,False,What architectural elements and assumptions must be captured to design simulation experiments that answer mission-level questions credibly?,What,DomainTopic=Mission engineering study design; simulation experiments informed by architecture | ScenarioType=Mission engineering study pattern (generalizable) + example(s) | Hits=[],What architectural elements and assumptions must be captured to design simulation experiments that answer mission-level questions credibly?,False
NDIA-2024-PENNOCK,NDIA-2024-PENNOCK-Q02,2024,NDIA Systems & Mission Engineering Conference,Conference Slides,Leveraging Architecture to Inform the Design of Simulation Experiments for Mission Engineering Studies,Pennock; McMullen (MITRE),Mission engineering study design; simulation experiments informed by architecture,Mission engineering study pattern (generalizable) + example(s),Architecture-driven experiment design; linking architectural models to simulation,Slides; workflow; experiment design guidance,How should simulations be parameterized and sampled to characterize mission performance across plausible operational envelopes derived from architecture?,Primary,Experiment design & uncertainty exploration,Scenario; Parameter; Uncertainty; Experiment; Measure,Confidence in mission performance estimates,Number of runs; design of experiments; variance,Methodology presentation with examples,Low-Medium,Open (slides),Public,Study design / analysis planning,Architecture-to-simulation linkage,https://ndiastorage.blob.core.usgovcloudapi.net/ndia/2024/SME/Tuesday/2B/2B-01_Pennock_McMullen.pdf,"Pennock, M., & McMullen, J. (2024). Leveraging Architecture to Inform the Design of Simulation Experiments for Mission Engineering Studies. NDIA Systems & Mission Engineering Conference.",[],False,How should simulations be parameterized and sampled to characterize mission performance across plausible operational envelopes derived from architecture?,False,How should simulations be parameterized and sampled to characterize mission performance across plausible operational envelopes derived from architecture?,How,DomainTopic=Mission engineering study design; simulation experiments informed by architecture | ScenarioType=Mission engineering study pattern (generalizable) + example(s) | Hits=[],How should simulations be parameterized and sampled to characterize mission performance across plausible operational envelopes derived from architecture?,False
JDMS-2009-DATAINIT-GOV,JDMS-2009-DATAINIT-GOV-Q01,2009,Journal of Defense Modeling and Simulation,Journal,Governance of Data Initialization for Service Oriented Architecture-based Military Simulation and Command and Control Federations,"Lanman, J. T.; Proctor, M. D.",Data governance; initialization for simulation/C2 federations; SOA,Federated simulation/C2 systems (architecture governance case framing),Conceptual reference model; governance framework,Governance reference model; data initialization lifecycle elements,What governance mechanisms are required to initialize and synchronize authoritative data across distributed simulation and real C2 systems without creating inconsistent operational pictures?,Primary,Interoperability & integration,Interoperability; Data; Governance; Baseline; Configuration; Architecture,,Data consistency; sync latency; error rate,Architecture/governance model paper,High,Open (PDF via SAGE),Unclassified,Federation data governance design,Governance reference model,https://journals.sagepub.com/doi/pdf/10.1177/1548512909344525,"Lanman, J. T., & Proctor, M. D. (2009). Governance of Data Initialization for Service Oriented Architecture-based Military Simulation and Command and Control Federations. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/1548512909344525",['C2'],True,What governance mechanisms are required to initialize and synchronize authoritative data across distributed simulation and real command and control systems without creating inconsistent operational pictures?,True,What governance mechanisms are required to initialize and synchronize authoritative data across distributed simulation and real command and control systems without creating inconsistent operational pictures?,What,DomainTopic=Data governance; initialization for simulation/C2 federations; SOA | ScenarioType=Federated simulation/C2 systems (architecture governance case framing) | Hits=['C2'],What governance mechanisms are required to initialize and synchronize authoritative data across distributed simulation and real C2 systems without creating inconsistent operational pictures?,False
JDMS-2009-DATAINIT-GOV,JDMS-2009-DATAINIT-GOV-Q02,2009,Journal of Defense Modeling and Simulation,Journal,Governance of Data Initialization for Service Oriented Architecture-based Military Simulation and Command and Control Federations,"Lanman, J. T.; Proctor, M. D.",Data governance; initialization for simulation/C2 federations; SOA,Federated simulation/C2 systems (architecture governance case framing),Conceptual reference model; governance framework,Governance reference model; data initialization lifecycle elements,"Where should responsibilities, interfaces, and standards be placed (organizationally and technically) so that initialization is repeatable across exercises and deployments?",Primary,Baseline & configuration management,Standard; Interface; Configuration; Stakeholder; Traceability; Baseline,,,Architecture/governance model paper,High,Open (PDF via SAGE),Unclassified,Authority & responsibility assignment,Process/governance model,https://journals.sagepub.com/doi/pdf/10.1177/1548512909344525,"Lanman, J. T., & Proctor, M. D. (2009). Governance of Data Initialization for Service Oriented Architecture-based Military Simulation and Command and Control Federations. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/1548512909344525",[],False,"Where should responsibilities, interfaces, and standards be placed (organizationally and technically) so that initialization is repeatable across exercises and deployments?",False,"Where should responsibilities, interfaces, and standards be placed (organizationally and technically) so that initialization is repeatable across exercises and deployments?",Where,DomainTopic=Data governance; initialization for simulation/C2 federations; SOA | ScenarioType=Federated simulation/C2 systems (architecture governance case framing) | Hits=[],"Where should responsibilities, interfaces, and standards be placed (organizationally and technically) so that initialization is repeatable across exercises and deployments?",False
JDMS-2009-DATAINIT-GOV,JDMS-2009-DATAINIT-GOV-Q03,2009,Journal of Defense Modeling and Simulation,Journal,Governance of Data Initialization for Service Oriented Architecture-based Military Simulation and Command and Control Federations,"Lanman, J. T.; Proctor, M. D.",Data governance; initialization for simulation/C2 federations; SOA,Federated simulation/C2 systems (architecture governance case framing),Conceptual reference model; governance framework,Governance reference model; data initialization lifecycle elements,What minimal set of compliance checks can detect dangerous initialization drift before it impacts training or real operations?,Secondary,"Test, evaluation & feedback",Test; Verification; Validation; Risk; Baseline; Data,,,Architecture/governance model paper,High,Open (PDF via SAGE),Unclassified,Pre-run verification checklist,V&V gate / checklist,https://journals.sagepub.com/doi/pdf/10.1177/1548512909344525,"Lanman, J. T., & Proctor, M. D. (2009). Governance of Data Initialization for Service Oriented Architecture-based Military Simulation and Command and Control Federations. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/1548512909344525",[],False,What minimal set of compliance checks can detect dangerous initialization drift before it impacts training or real operations?,False,What minimal set of compliance checks can detect dangerous initialization drift before it impacts training or real operations?,What,DomainTopic=Data governance; initialization for simulation/C2 federations; SOA | ScenarioType=Federated simulation/C2 systems (architecture governance case framing) | Hits=[],What minimal set of compliance checks can detect dangerous initialization drift before it impacts training or real operations?,False
INSIGHT-2016-SoS-AWB,INSIGHT-2016-SoS-AWB-Q01,2016,INSIGHT (INCOSE),Magazine/Professional,An SoS Analytical Workbench Approach to Architectural Analysis and Evolution,"DeLaurentis, D.; et al.",System-of-systems architecture analysis; evolution planning,Naval warfare SoS case framing (architecture evolution),SoS analytic workbench; architectural analysis methods,SoS architecture models; analysis workbench concept,"How can an SoS analytical workbench support architectural analysis and evolution decisions for a mission context (e.g., naval warfare) with many interacting systems?",Primary,Architecture & integration for mission effects,Architecture; System; Dependency; Interoperability; Decision; Change,SoS mission effectiveness; coverage,,Applied method paper (reprinted),Medium,Open (PDF),Unclassified,SoS architecture evolution decision,SoS workbench / architectural analysis,https://www.incose.org/docs/default-source/publication-products/insight/insight_vol_28_issue_1.pdf?sfvrsn=5e878bc5_4,"DeLaurentis, D., et al. (2016). An SoS Analytical Workbench Approach to Architectural Analysis and Evolution. INSIGHT (reprinted in Vol. 28, Issue 1, 2025). INCOSE.",[],False,"How can an SoS analytical workbench support architectural analysis and evolution decisions for a mission context (e.g., naval warfare) with many interacting systems?",False,"How can an SoS analytical workbench support architectural analysis and evolution decisions for a mission context (e.g., naval warfare) with many interacting systems?",How,DomainTopic=System-of-systems architecture analysis; evolution planning | ScenarioType=Naval warfare SoS case framing (architecture evolution) | Hits=[],"How can an SoS analytical workbench support architectural analysis and evolution decisions for a mission context (e.g., naval warfare) with many interacting systems?",False
INSIGHT-2016-SoS-AWB,INSIGHT-2016-SoS-AWB-Q02,2016,INSIGHT (INCOSE),Magazine/Professional,An SoS Analytical Workbench Approach to Architectural Analysis and Evolution,"DeLaurentis, D.; et al.",System-of-systems architecture analysis; evolution planning,Naval warfare SoS case framing (architecture evolution),SoS analytic workbench; architectural analysis methods,SoS architecture models; analysis workbench concept,"Which interdependencies and critical nodes dominate mission outcomes, and how should they be prioritized for modernization or protection?",Primary,Interdependencies & criticality,Dependency; Criticality; Bottleneck; Risk; Architecture; Tradeoff,,,Applied method paper (reprinted),Medium,Open (PDF),Unclassified,Criticality-based investment,Network/architecture analysis,https://www.incose.org/docs/default-source/publication-products/insight/insight_vol_28_issue_1.pdf?sfvrsn=5e878bc5_4,"DeLaurentis, D., et al. (2016). An SoS Analytical Workbench Approach to Architectural Analysis and Evolution. INSIGHT (reprinted in Vol. 28, Issue 1, 2025). INCOSE.",[],False,"Which interdependencies and critical nodes dominate mission outcomes, and how should they be prioritized for modernization or protection?",False,"Which interdependencies and critical nodes dominate mission outcomes, and how should they be prioritized for modernization or protection?",Which,DomainTopic=System-of-systems architecture analysis; evolution planning | ScenarioType=Naval warfare SoS case framing (architecture evolution) | Hits=[],"Which interdependencies and critical nodes dominate mission outcomes, and how should they be prioritized for modernization or protection?",False
INSIGHT-2016-SoS-AWB,INSIGHT-2016-SoS-AWB-Q03,2016,INSIGHT (INCOSE),Magazine/Professional,An SoS Analytical Workbench Approach to Architectural Analysis and Evolution,"DeLaurentis, D.; et al.",System-of-systems architecture analysis; evolution planning,Naval warfare SoS case framing (architecture evolution),SoS analytic workbench; architectural analysis methods,SoS architecture models; analysis workbench concept,What baseline and configuration artifacts are required so that SoS analyses remain comparable across time and tool updates?,Secondary,Baseline & configuration management,Baseline; Configuration; Artifact; Traceability; Change; Model,,,Applied method paper (reprinted),Medium,Open (PDF),Unclassified,Model baseline governance,Configuration/provenance,https://www.incose.org/docs/default-source/publication-products/insight/insight_vol_28_issue_1.pdf?sfvrsn=5e878bc5_4,"DeLaurentis, D., et al. (2016). An SoS Analytical Workbench Approach to Architectural Analysis and Evolution. INSIGHT (reprinted in Vol. 28, Issue 1, 2025). INCOSE.",[],False,What baseline and configuration artifacts are required so that SoS analyses remain comparable across time and tool updates?,False,What baseline and configuration artifacts are required so that SoS analyses remain comparable across time and tool updates?,What,DomainTopic=System-of-systems architecture analysis; evolution planning | ScenarioType=Naval warfare SoS case framing (architecture evolution) | Hits=[],What baseline and configuration artifacts are required so that SoS analyses remain comparable across time and tool updates?,False
INSIGHT-2017-OPS-PERSPECTIVES-RES,INSIGHT-2017-OPS-PERSPECTIVES-RES-Q01,2017,INSIGHT (INCOSE),Magazine/Professional,Bringing Operational Perspectives into the Analysis of Engineered Resilient Systems,"Sitterle, V.; et al.",Engineered resilience; operational perspectives; mission assurance,Defense-relevant resilience analysis framing,Operationally anchored resilience analysis; perspective integration,Operational perspective constructs; analysis approach,"What operational perspectives (constraints, tactics, human performance, sustainment realities) must be incorporated so resilience analysis reflects day-to-day mission execution?",Primary,Risk mitigation & resilience,Resilience; CONOPS; Constraint; Stakeholder; Risk; Scenario,Mission continuity; time-to-recover,,Applied method (reprinted),Medium,Open (PDF),Unclassified,Resilience analysis scope definition,Operationally anchored resilience analysis,https://www.incose.org/docs/default-source/publication-products/insight/insight_vol_28_issue_1.pdf?sfvrsn=5e878bc5_4,"Sitterle, V., et al. (2017). Bringing Operational Perspectives into the Analysis of Engineered Resilient Systems. INSIGHT (reprinted in Vol. 28, Issue 1, 2025). INCOSE.",[],False,"What operational perspectives (constraints, tactics, human performance, sustainment realities) must be incorporated so resilience analysis reflects day-to-day mission execution?",False,"What operational perspectives (constraints, tactics, human performance, sustainment realities) must be incorporated so resilience analysis reflects day-to-day mission execution?",What,DomainTopic=Engineered resilience; operational perspectives; mission assurance | ScenarioType=Defense-relevant resilience analysis framing | Hits=[],"What operational perspectives (constraints, tactics, human performance, sustainment realities) must be incorporated so resilience analysis reflects day-to-day mission execution?",False
INSIGHT-2017-OPS-PERSPECTIVES-RES,INSIGHT-2017-OPS-PERSPECTIVES-RES-Q02,2017,INSIGHT (INCOSE),Magazine/Professional,Bringing Operational Perspectives into the Analysis of Engineered Resilient Systems,"Sitterle, V.; et al.",Engineered resilience; operational perspectives; mission assurance,Defense-relevant resilience analysis framing,Operationally anchored resilience analysis; perspective integration,Operational perspective constructs; analysis approach,How do different stakeholder perspectives change which losses are unacceptable and which resilience investments are worth funding?,Primary,Portfolio governance & review questions,Stakeholder; Loss; Decision; Value; Tradeoff; Portfolio,,,Applied method (reprinted),Medium,Open (PDF),Unclassified,Investment prioritization,Multi-perspective value/risk model,https://www.incose.org/docs/default-source/publication-products/insight/insight_vol_28_issue_1.pdf?sfvrsn=5e878bc5_4,"Sitterle, V., et al. (2017). Bringing Operational Perspectives into the Analysis of Engineered Resilient Systems. INSIGHT (reprinted in Vol. 28, Issue 1, 2025). INCOSE.",[],False,How do different stakeholder perspectives change which losses are unacceptable and which resilience investments are worth funding?,False,How do different stakeholder perspectives change which losses are unacceptable and which resilience investments are worth funding?,How,DomainTopic=Engineered resilience; operational perspectives; mission assurance | ScenarioType=Defense-relevant resilience analysis framing | Hits=[],How do different stakeholder perspectives change which losses are unacceptable and which resilience investments are worth funding?,False
INSIGHT-2017-OPS-PERSPECTIVES-RES,INSIGHT-2017-OPS-PERSPECTIVES-RES-Q03,2017,INSIGHT (INCOSE),Magazine/Professional,Bringing Operational Perspectives into the Analysis of Engineered Resilient Systems,"Sitterle, V.; et al.",Engineered resilience; operational perspectives; mission assurance,Defense-relevant resilience analysis framing,Operationally anchored resilience analysis; perspective integration,Operational perspective constructs; analysis approach,"What evidence types (training, ops logs, exercises) are suitable to validate resilience claims and update models over time?",Secondary,Traceability & evidence management,Evidence; Validation; Change; Assumption; Traceability; Test,,,Applied method (reprinted),Medium,Open (PDF),Unclassified,Resilience evidence plan,Evidence/learning loop,https://www.incose.org/docs/default-source/publication-products/insight/insight_vol_28_issue_1.pdf?sfvrsn=5e878bc5_4,"Sitterle, V., et al. (2017). Bringing Operational Perspectives into the Analysis of Engineered Resilient Systems. INSIGHT (reprinted in Vol. 28, Issue 1, 2025). INCOSE.",[],False,"What evidence types (training, ops logs, exercises) are suitable to validate resilience claims and update models over time?",False,"What evidence types (training, ops logs, exercises) are suitable to validate resilience claims and update models over time?",What,DomainTopic=Engineered resilience; operational perspectives; mission assurance | ScenarioType=Defense-relevant resilience analysis framing | Hits=[],"What evidence types (training, ops logs, exercises) are suitable to validate resilience claims and update models over time?",False
INSIGHT-2018-FORMAL-MODELING-RES,INSIGHT-2018-FORMAL-MODELING-RES-Q01,2018,INSIGHT (INCOSE),Magazine/Professional,Extending Formal Modeling for Resilient Systems Design,"Madni, A. M.; et al.",Formal modeling; resilient design; multi-UAV swarm example,Example-driven method (UAV swarm resiliency),Formal modeling extensions; resilience modeling,Formal models; resilience patterns,"How can formal modeling be extended to capture resilience behaviors (avoid, withstand, recover, adapt) and enable design-time trade studies?",Primary,Ilities trade-space,Resilience; Tradeoff; Model; Architecture; Requirement; DesignChange,Resilience score; mission success under disruption,,Method + example (reprinted),Medium,Open (PDF),Unclassified,Resilience trade study,Formal modeling + resilience patterns,https://www.incose.org/docs/default-source/publication-products/insight/insight_vol_28_issue_1.pdf?sfvrsn=5e878bc5_4,"Madni, A. M., et al. (2018). Extending Formal Modeling for Resilient Systems Design. INSIGHT (reprinted in Vol. 28, Issue 1, 2025). INCOSE.",[],False,"How can formal modeling be extended to capture resilience behaviors (avoid, withstand, recover, adapt) and enable design-time trade studies?",False,"How can formal modeling be extended to capture resilience behaviors (avoid, withstand, recover, adapt) and enable design-time trade studies?",How,DomainTopic=Formal modeling; resilient design; multi-UAV swarm example | ScenarioType=Example-driven method (UAV swarm resiliency) | Hits=[],"How can formal modeling be extended to capture resilience behaviors (avoid, withstand, recover, adapt) and enable design-time trade studies?",False
INSIGHT-2018-FORMAL-MODELING-RES,INSIGHT-2018-FORMAL-MODELING-RES-Q02,2018,INSIGHT (INCOSE),Magazine/Professional,Extending Formal Modeling for Resilient Systems Design,"Madni, A. M.; et al.",Formal modeling; resilient design; multi-UAV swarm example,Example-driven method (UAV swarm resiliency),Formal modeling extensions; resilience modeling,Formal models; resilience patterns,"In a multi-UAV swarm context, which architectural patterns provide robust mission effects under failures or adversary actions?",Primary,Architecture & integration for mission effects,Architecture; System; Threat; Vulnerability; Tradeoff; Capability,,,Method + example (reprinted),Medium,Open (PDF),Unclassified,Swarm architecture selection,Formal model analysis,https://www.incose.org/docs/default-source/publication-products/insight/insight_vol_28_issue_1.pdf?sfvrsn=5e878bc5_4,"Madni, A. M., et al. (2018). Extending Formal Modeling for Resilient Systems Design. INSIGHT (reprinted in Vol. 28, Issue 1, 2025). INCOSE.",['UAV'],True,"In a multi-platform swarm context, which architectural patterns provide robust mission effects under failures or adversary actions?",True,"In a multi-platform swarm context, which architectural patterns provide robust mission effects under failures or adversary actions?",How,DomainTopic=Formal modeling; resilient design; multi-UAV swarm example | ScenarioType=Example-driven method (UAV swarm resiliency) | Hits=['UAV'],"In a multi-UAV swarm context, which architectural patterns provide robust mission effects under failures or adversary actions?",False
INSIGHT-2018-FORMAL-MODELING-RES,INSIGHT-2018-FORMAL-MODELING-RES-Q03,2018,INSIGHT (INCOSE),Magazine/Professional,Extending Formal Modeling for Resilient Systems Design,"Madni, A. M.; et al.",Formal modeling; resilient design; multi-UAV swarm example,Example-driven method (UAV swarm resiliency),Formal modeling extensions; resilience modeling,Formal models; resilience patterns,"What assumptions about environment and adversary behavior are most likely to invalidate formal resilience conclusions, and how should they be bounded?",Secondary,"Uncertainty, sensitivity & decision robustness",Assumption; Uncertainty; Threat; Scenario; Sensitivity; Validation,,,Method + example (reprinted),Medium,Open (PDF),Unclassified,Assumption bounding,Sensitivity / uncertainty analysis,https://www.incose.org/docs/default-source/publication-products/insight/insight_vol_28_issue_1.pdf?sfvrsn=5e878bc5_4,"Madni, A. M., et al. (2018). Extending Formal Modeling for Resilient Systems Design. INSIGHT (reprinted in Vol. 28, Issue 1, 2025). INCOSE.",[],False,"What assumptions about environment and adversary behavior are most likely to invalidate formal resilience conclusions, and how should they be bounded?",False,"What assumptions about environment and adversary behavior are most likely to invalidate formal resilience conclusions, and how should they be bounded?",What,DomainTopic=Formal modeling; resilient design; multi-UAV swarm example | ScenarioType=Example-driven method (UAV swarm resiliency) | Hits=[],"What assumptions about environment and adversary behavior are most likely to invalidate formal resilience conclusions, and how should they be bounded?",False
DAU-DAMAG-2020-PORTFOLIO-MODEL,DAU-DAMAG-2020-PORTFOLIO-MODEL-Q01,2020,Defense Acquisition Magazine (DAU),Magazine/Trade,A Portfolio Management-Based Acquisition Model?,"Schultz, B.",Acquisition reform; portfolio management; capability gaps prioritization,Conceptual with illustrative defense acquisition examples,Portfolio management framing; business case alternatives; governance,Process model; decision points and measures,How can capability gaps be prioritized and translated into portfolio business cases that remain valid under changing threats and budgets?,Primary,Portfolio governance & review questions,Portfolio; Threat; Cost; Decision; Uncertainty; Stakeholder,,,Practice-oriented conceptual argument,High,Open (web),Unclassified,Portfolio prioritization process,Portfolio management model,https://www.dau.edu/library/damag/january-february2020/portfolio-management-based-acquisition-model,"Schultz, B. (2020). A Portfolio Management-Based Acquisition Model? Defense Acquisition Magazine (DAU).",[],False,How can capability gaps be prioritized and translated into portfolio business cases that remain valid under changing threats and budgets?,False,How can capability gaps be prioritized and translated into portfolio business cases that remain valid under changing threats and budgets?,How,DomainTopic=Acquisition reform; portfolio management; capability gaps prioritization | ScenarioType=Conceptual with illustrative defense acquisition examples | Hits=[],How can capability gaps be prioritized and translated into portfolio business cases that remain valid under changing threats and budgets?,False
DAU-DAMAG-2020-PORTFOLIO-MODEL,DAU-DAMAG-2020-PORTFOLIO-MODEL-Q02,2020,Defense Acquisition Magazine (DAU),Magazine/Trade,A Portfolio Management-Based Acquisition Model?,"Schultz, B.",Acquisition reform; portfolio management; capability gaps prioritization,Conceptual with illustrative defense acquisition examples,Portfolio management framing; business case alternatives; governance,Process model; decision points and measures,What decision cadence and governance roles enable portfolio rebalancing while maintaining accountability and traceability?,Primary,Baseline & configuration management,Baseline; Governance; Traceability; Decision; Change; Stakeholder,,,Practice-oriented conceptual argument,High,Open (web),Unclassified,Rebalancing governance,Process model,https://www.dau.edu/library/damag/january-february2020/portfolio-management-based-acquisition-model,"Schultz, B. (2020). A Portfolio Management-Based Acquisition Model? Defense Acquisition Magazine (DAU).",[],False,What decision cadence and governance roles enable portfolio rebalancing while maintaining accountability and traceability?,False,What decision cadence and governance roles enable portfolio rebalancing while maintaining accountability and traceability?,What,DomainTopic=Acquisition reform; portfolio management; capability gaps prioritization | ScenarioType=Conceptual with illustrative defense acquisition examples | Hits=[],What decision cadence and governance roles enable portfolio rebalancing while maintaining accountability and traceability?,False
DAU-DAMAG-2020-PORTFOLIO-MODEL,DAU-DAMAG-2020-PORTFOLIO-MODEL-Q03,2020,Defense Acquisition Magazine (DAU),Magazine/Trade,A Portfolio Management-Based Acquisition Model?,"Schultz, B.",Acquisition reform; portfolio management; capability gaps prioritization,Conceptual with illustrative defense acquisition examples,Portfolio management framing; business case alternatives; governance,Process model; decision points and measures,"How should trade-space evidence (cost, schedule, performance, risk) be packaged to support senior decision authorities across the enterprise?",Secondary,Tradeoffs & decision robustness,Tradeoff; Evidence; Cost; Schedule; Risk; Decision,,,Practice-oriented conceptual argument,High,Open (web),Unclassified,Decision package definition,Decision-support artifacts,https://www.dau.edu/library/damag/january-february2020/portfolio-management-based-acquisition-model,"Schultz, B. (2020). A Portfolio Management-Based Acquisition Model? Defense Acquisition Magazine (DAU).",[],False,"How should trade-space evidence (cost, schedule, performance, risk) be packaged to support senior decision authorities across the enterprise?",False,"How should trade-space evidence (cost, schedule, performance, risk) be packaged to support senior decision authorities across the enterprise?",How,DomainTopic=Acquisition reform; portfolio management; capability gaps prioritization | ScenarioType=Conceptual with illustrative defense acquisition examples | Hits=[],"How should trade-space evidence (cost, schedule, performance, risk) be packaged to support senior decision authorities across the enterprise?",False
DAU-DAMAG-2020-VATEP-TX,DAU-DAMAG-2020-VATEP-TX-Q01,2020,Defense Acquisition Magazine (DAU),Magazine/Trade,Best Value Awards (T‑X / VATEP case study),"Moore, (see article)",Source selection; best value tradeoffs; VATEP application,Real program procurement case (T‑X procurement),Source-selection process analysis; value adjustment method description,VATEP decrement process; evaluation framework,How can a source selection quantify the value of superior performance and relate it to cost in a way that is transparent and defensible to decision authorities?,Primary,Tradeoffs & decision robustness,Tradeoff; Cost; Decision; Value; Stakeholder; Traceability,Value-adjusted cost; mission benefit,,Case study analysis,Medium (process described),Open (web),Unclassified,Source selection tradeoff decision,Value modeling / VATEP,https://www.dau.edu/library/damag/july-august2020/best-value-awards,Moore. (2020). Best Value Awards (T‑X / VATEP case study). Defense Acquisition Magazine (DAU).,[],False,How can a source selection quantify the value of superior performance and relate it to cost in a way that is transparent and defensible to decision authorities?,False,How can a source selection quantify the value of superior performance and relate it to cost in a way that is transparent and defensible to decision authorities?,How,DomainTopic=Source selection; best value tradeoffs; VATEP application | ScenarioType=Real program procurement case (T‑X procurement) | Hits=[],How can a source selection quantify the value of superior performance and relate it to cost in a way that is transparent and defensible to decision authorities?,False
DAU-DAMAG-2020-VATEP-TX,DAU-DAMAG-2020-VATEP-TX-Q02,2020,Defense Acquisition Magazine (DAU),Magazine/Trade,Best Value Awards (T‑X / VATEP case study),"Moore, (see article)",Source selection; best value tradeoffs; VATEP application,Real program procurement case (T‑X procurement),Source-selection process analysis; value adjustment method description,VATEP decrement process; evaluation framework,"What evaluation measures and decrement rules best reflect operational impact (e.g., training outcomes, readiness) for a platform procurement?",Primary,Architecture/CONOPS comparison,Measure; Capability; CONOPS; Value; Requirement; Decision,,,Case study analysis,Medium (process described),Open (web),Unclassified,Evaluation rubric definition,Metric/rubric design,https://www.dau.edu/library/damag/july-august2020/best-value-awards,Moore. (2020). Best Value Awards (T‑X / VATEP case study). Defense Acquisition Magazine (DAU).,[],False,"What evaluation measures and decrement rules best reflect operational impact (e.g., training outcomes, readiness) for a platform procurement?",False,"What evaluation measures and decrement rules best reflect operational impact (e.g., training outcomes, readiness) for a platform procurement?",What,DomainTopic=Source selection; best value tradeoffs; VATEP application | ScenarioType=Real program procurement case (T‑X procurement) | Hits=[],"What evaluation measures and decrement rules best reflect operational impact (e.g., training outcomes, readiness) for a platform procurement?",False
DAU-DAMAG-2020-VATEP-TX,DAU-DAMAG-2020-VATEP-TX-Q03,2020,Defense Acquisition Magazine (DAU),Magazine/Trade,Best Value Awards (T‑X / VATEP case study),"Moore, (see article)",Source selection; best value tradeoffs; VATEP application,Real program procurement case (T‑X procurement),Source-selection process analysis; value adjustment method description,VATEP decrement process; evaluation framework,How should the acquisition team document assumptions and sensitivity to protect the decision against protests and future changes in assumptions?,Secondary,Study design & validity,Assumption; Sensitivity; Evidence; Traceability; Risk; Decision,,,Case study analysis,Medium (process described),Open (web),Unclassified,Decision defensibility strategy,Sensitivity / documentation,https://www.dau.edu/library/damag/july-august2020/best-value-awards,Moore. (2020). Best Value Awards (T‑X / VATEP case study). Defense Acquisition Magazine (DAU).,[],False,How should the acquisition team document assumptions and sensitivity to protect the decision against protests and future changes in assumptions?,False,How should the acquisition team document assumptions and sensitivity to protect the decision against protests and future changes in assumptions?,How,DomainTopic=Source selection; best value tradeoffs; VATEP application | ScenarioType=Real program procurement case (T‑X procurement) | Hits=[],How should the acquisition team document assumptions and sensitivity to protect the decision against protests and future changes in assumptions?,False
JDMS-2020-CYBER-RISK-EST,JDMS-2020-CYBER-RISK-EST-Q01,2020,Journal of Defense Modeling and Simulation,Journal,Estimation of cyber network risk using importance splitting for rare events,"Krall, J.; et al.",Cyber risk quantification; rare event simulation; network security,Network risk modeling with rare-event estimation,Rare-event simulation; importance splitting; probabilistic risk estimation,Risk estimation methodology; simulation experiment results,"How can we estimate low-probability, high-consequence cyber events efficiently enough to support operational decision-making and architecture reviews?",Primary,"Uncertainty, sensitivity & decision robustness",Risk; Uncertainty; Simulation; Threat; Sensitivity; Decision,Probability of mission-impacting compromise,,Method + experimental evaluation,Medium,Open (PDF via SAGE),Unclassified,Risk estimation method selection,Rare-event simulation / importance splitting,https://journals.sagepub.com/doi/pdf/10.1177/1548512920934551,"Krall, J., et al. (2020). Estimation of cyber network risk using importance splitting for rare events. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/1548512920934551",[],False,"How can we estimate low-probability, high-consequence cyber events efficiently enough to support operational decision-making and architecture reviews?",False,"How can we estimate low-probability, high-consequence cyber events efficiently enough to support operational decision-making and architecture reviews?",How,DomainTopic=Cyber risk quantification; rare event simulation; network security | ScenarioType=Network risk modeling with rare-event estimation | Hits=[],"How can we estimate low-probability, high-consequence cyber events efficiently enough to support operational decision-making and architecture reviews?",False
JDMS-2020-CYBER-RISK-EST,JDMS-2020-CYBER-RISK-EST-Q02,2020,Journal of Defense Modeling and Simulation,Journal,Estimation of cyber network risk using importance splitting for rare events,"Krall, J.; et al.",Cyber risk quantification; rare event simulation; network security,Network risk modeling with rare-event estimation,Rare-event simulation; importance splitting; probabilistic risk estimation,Risk estimation methodology; simulation experiment results,Which network defenses or architectural changes produce the largest marginal reduction in rare-event risk?,Primary,Value of design changes,DesignChange; Architecture; Tradeoff; Cost; Risk; Vulnerability,,,Method + experimental evaluation,Medium,Open (PDF via SAGE),Unclassified,Defense investment prioritization,Risk delta / marginal analysis,https://journals.sagepub.com/doi/pdf/10.1177/1548512920934551,"Krall, J., et al. (2020). Estimation of cyber network risk using importance splitting for rare events. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/1548512920934551",[],False,Which network defenses or architectural changes produce the largest marginal reduction in rare-event risk?,False,Which network defenses or architectural changes produce the largest marginal reduction in rare-event risk?,Which,DomainTopic=Cyber risk quantification; rare event simulation; network security | ScenarioType=Network risk modeling with rare-event estimation | Hits=[],Which network defenses or architectural changes produce the largest marginal reduction in rare-event risk?,False
JDMS-2020-CYBER-RISK-EST,JDMS-2020-CYBER-RISK-EST-Q03,2020,Journal of Defense Modeling and Simulation,Journal,Estimation of cyber network risk using importance splitting for rare events,"Krall, J.; et al.",Cyber risk quantification; rare event simulation; network security,Network risk modeling with rare-event estimation,Rare-event simulation; importance splitting; probabilistic risk estimation,Risk estimation methodology; simulation experiment results,"What assumptions about attacker behavior and network state dominate the risk estimate, and how should they be stress-tested?",Secondary,Experiment design & uncertainty exploration,Assumption; Threat; Uncertainty; Scenario; Sensitivity; Validation,,,Method + experimental evaluation,Medium,Open (PDF via SAGE),Unclassified,Assumption stress-test plan,Uncertainty exploration,https://journals.sagepub.com/doi/pdf/10.1177/1548512920934551,"Krall, J., et al. (2020). Estimation of cyber network risk using importance splitting for rare events. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/1548512920934551",[],False,"What assumptions about attacker behavior and network state dominate the risk estimate, and how should they be stress-tested?",False,"What assumptions about attacker behavior and network state dominate the risk estimate, and how should they be stress-tested?",What,DomainTopic=Cyber risk quantification; rare event simulation; network security | ScenarioType=Network risk modeling with rare-event estimation | Hits=[],"What assumptions about attacker behavior and network state dominate the risk estimate, and how should they be stress-tested?",False
SERC-2020-TR-005,SERC-2020-TR-005-Q01,2020,SERC Technical Report,Technical Report,Methods to Evaluate Cost/Technical Risk and Opportunity Decisions for Mission Assurance (ART-004),Systems Engineering Research Center (SERC),Mission assurance / cyber resiliency; architecture risk trade-offs; loss-driven analysis,Demonstrated case study with meta-model and tool integration (cyber-physical resilience),Model-based mission assurance; meta-modeling; risk analysis; architecture trade-space,MA meta-model; MBSE model; threat/attack vectors; resilient modes; prioritization metrics,"Given an identified set of losses and adversary actions, which resilience modes and design changes provide the best risk reduction per unit cost (and where are diminishing returns)?",Primary,Risk mitigation & resilience,Risk; Vulnerability; Threat; Tradeoff; Cost; DesignChange; Decision,Expected loss avoided; mission success probability,,Case study demonstration + methodology description,Medium (meta-model described; tool specifics limited),Open (PDF),Unclassified,Resilience architecture selection,MBSE + risk analysis (mission assurance),https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1593531986.SERC_A013_ART-004_FinalReport_SERC-2020-TR-005.pdf,Systems Engineering Research Center (SERC). (2020). Methods to Evaluate Cost/Technical Risk and Opportunity Decisions for Mission Assurance (SERC-2020-TR-005).,[],False,"Given an identified set of losses and adversary actions, which resilience modes and design changes provide the best risk reduction per unit cost (and where are diminishing returns)?",False,"How should given an identified set of losses and adversary actions, which resilience modes and design changes provide the best risk reduction per unit cost (and where are diminishing returns)?",How,DomainTopic=Mission assurance / cyber resiliency; architecture risk trade-offs; loss-driven analysis | ScenarioType=Demonstrated case study with meta-model and tool integration (cyber-physical resilience) | Hits=[],"Given an identified set of losses and adversary actions, which resilience modes and design changes provide the best risk reduction per unit cost (and where are diminishing returns)?",False
SERC-2020-TR-005,SERC-2020-TR-005-Q02,2020,SERC Technical Report,Technical Report,Methods to Evaluate Cost/Technical Risk and Opportunity Decisions for Mission Assurance (ART-004),Systems Engineering Research Center (SERC),Mission assurance / cyber resiliency; architecture risk trade-offs; loss-driven analysis,Demonstrated case study with meta-model and tool integration (cyber-physical resilience),Model-based mission assurance; meta-modeling; risk analysis; architecture trade-space,MA meta-model; MBSE model; threat/attack vectors; resilient modes; prioritization metrics,"How do we represent mission-owner, systems-engineer, and red-team perspectives in one model so that threat likelihood, severity, and priorities are comparable and reviewable?",Primary,Traceability & evidence management,Stakeholder; Traceability; Threat; Risk; Artifact; Model,,Consistency of risk rankings; review cycle time,Case study demonstration + methodology description,Medium (meta-model described; tool specifics limited),Open (PDF),Unclassified,Common risk model governance,Meta-model integration,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1593531986.SERC_A013_ART-004_FinalReport_SERC-2020-TR-005.pdf,Systems Engineering Research Center (SERC). (2020). Methods to Evaluate Cost/Technical Risk and Opportunity Decisions for Mission Assurance (SERC-2020-TR-005).,[],False,"How do we represent mission-owner, systems-engineer, and red-team perspectives in one model so that threat likelihood, severity, and priorities are comparable and reviewable?",False,"How do we represent mission-owner, systems-engineer, and red-team perspectives in one model so that threat likelihood, severity, and priorities are comparable and reviewable?",How,DomainTopic=Mission assurance / cyber resiliency; architecture risk trade-offs; loss-driven analysis | ScenarioType=Demonstrated case study with meta-model and tool integration (cyber-physical resilience) | Hits=[],"How do we represent mission-owner, systems-engineer, and red-team perspectives in one model so that threat likelihood, severity, and priorities are comparable and reviewable?",False
SERC-2020-TR-005,SERC-2020-TR-005-Q03,2020,SERC Technical Report,Technical Report,Methods to Evaluate Cost/Technical Risk and Opportunity Decisions for Mission Assurance (ART-004),Systems Engineering Research Center (SERC),Mission assurance / cyber resiliency; architecture risk trade-offs; loss-driven analysis,Demonstrated case study with meta-model and tool integration (cyber-physical resilience),Model-based mission assurance; meta-modeling; risk analysis; architecture trade-space,MA meta-model; MBSE model; threat/attack vectors; resilient modes; prioritization metrics,"What meta-model constructs are required to propagate a cyber-physical attack scenario into mission-level effects and requirements, without over-modeling?",Secondary,Architecture & integration for mission effects,Architecture; Threat; Vulnerability; Requirement; Scenario; Dependency,,,Case study demonstration + methodology description,Medium (meta-model described; tool specifics limited),Open (PDF),Unclassified,Model scope/abstraction choice,Meta-model / architectural mapping,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1593531986.SERC_A013_ART-004_FinalReport_SERC-2020-TR-005.pdf,Systems Engineering Research Center (SERC). (2020). Methods to Evaluate Cost/Technical Risk and Opportunity Decisions for Mission Assurance (SERC-2020-TR-005).,[],False,"What meta-model constructs are required to propagate a cyber-physical attack scenario into mission-level effects and requirements, without over-modeling?",False,"What meta-model constructs are required to propagate a cyber-physical attack scenario into mission-level effects and requirements, without over-modeling?",What,DomainTopic=Mission assurance / cyber resiliency; architecture risk trade-offs; loss-driven analysis | ScenarioType=Demonstrated case study with meta-model and tool integration (cyber-physical resilience) | Hits=[],"What meta-model constructs are required to propagate a cyber-physical attack scenario into mission-level effects and requirements, without over-modeling?",False
SERC-2021-TR-015,SERC-2021-TR-015-Q01,2021,SERC Technical Report,Technical Report,Developmental Test and Evaluation (DTE&A) and Cyberattack Resilient Systems (WRT-1022),Systems Engineering Research Center (SERC),Operational resilience; cyberattack-resilient systems; DT&E measurement,Reference use case + measurement framework for DT&E,Resilience metrics; test design guidance; measurement framework for DT&E,Operational resilience measures; DT&E guidance; illustrative examples,"What operational resilience measures should DT&E collect to provide decision-quality evidence that a system can withstand, recover from, and adapt to cyberattack?",Primary,"Test, evaluation & feedback",Test; Measure; Risk; Resilience; Threat; Validation,Mission continuation time; recovery time; degradation limits,,Method/guidance with examples,Medium,Open (PDF),Unclassified,Test plan & metric selection,Test/evaluation measurement framework,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1623674894.SERC_WRT-1022_A013_FinalReport_SERC-2021-TR-015.pdf,Systems Engineering Research Center (SERC). (2021). Developmental Test and Evaluation (DTE&A) and Cyberattack Resilient Systems (SERC-2021-TR-015).,[],False,"What operational resilience measures should DT&E collect to provide decision-quality evidence that a system can withstand, recover from, and adapt to cyberattack?",False,"What operational resilience measures should DT&E collect to provide decision-quality evidence that a system can withstand, recover from, and adapt to cyberattack?",What,DomainTopic=Operational resilience; cyberattack-resilient systems; DT&E measurement | ScenarioType=Reference use case + measurement framework for DT&E | Hits=[],"What operational resilience measures should DT&E collect to provide decision-quality evidence that a system can withstand, recover from, and adapt to cyberattack?",True
SERC-2021-TR-015,SERC-2021-TR-015-Q02,2021,SERC Technical Report,Technical Report,Developmental Test and Evaluation (DTE&A) and Cyberattack Resilient Systems (WRT-1022),Systems Engineering Research Center (SERC),Operational resilience; cyberattack-resilient systems; DT&E measurement,Reference use case + measurement framework for DT&E,Resilience metrics; test design guidance; measurement framework for DT&E,Operational resilience measures; DT&E guidance; illustrative examples,"How can we design DT&E scenarios that are representative of real cyberattack pathways while remaining safe, repeatable, and cost-bounded?",Primary,Experiment design & uncertainty exploration,Scenario; Test; Constraint; Threat; Uncertainty; Cost,,Scenario coverage; execution cost,Method/guidance with examples,Medium,Open (PDF),Unclassified,Scenario set design for DT&E,Scenario-based test design,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1623674894.SERC_WRT-1022_A013_FinalReport_SERC-2021-TR-015.pdf,Systems Engineering Research Center (SERC). (2021). Developmental Test and Evaluation (DTE&A) and Cyberattack Resilient Systems (SERC-2021-TR-015).,[],False,"How can we design DT&E scenarios that are representative of real cyberattack pathways while remaining safe, repeatable, and cost-bounded?",False,"How can we design DT&E scenarios that are representative of real cyberattack pathways while remaining safe, repeatable, and cost-bounded?",How,DomainTopic=Operational resilience; cyberattack-resilient systems; DT&E measurement | ScenarioType=Reference use case + measurement framework for DT&E | Hits=[],"How can we design DT&E scenarios that are representative of real cyberattack pathways while remaining safe, repeatable, and cost-bounded?",True
SERC-2021-TR-015,SERC-2021-TR-015-Q03,2021,SERC Technical Report,Technical Report,Developmental Test and Evaluation (DTE&A) and Cyberattack Resilient Systems (WRT-1022),Systems Engineering Research Center (SERC),Operational resilience; cyberattack-resilient systems; DT&E measurement,Reference use case + measurement framework for DT&E,Resilience metrics; test design guidance; measurement framework for DT&E,Operational resilience measures; DT&E guidance; illustrative examples,"What feedback loops are needed to connect DT&E resilience findings back into requirements, architecture updates, and operational CONOPS changes?",Secondary,Requirements evolution & architecture,Requirement; Architecture; Change; CONOPS; Verification; Validation,,,Method/guidance with examples,Medium,Open (PDF),Unclassified,Requirements/architecture update governance,Closed-loop V&V + change control,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1623674894.SERC_WRT-1022_A013_FinalReport_SERC-2021-TR-015.pdf,Systems Engineering Research Center (SERC). (2021). Developmental Test and Evaluation (DTE&A) and Cyberattack Resilient Systems (SERC-2021-TR-015).,[],False,"What feedback loops are needed to connect DT&E resilience findings back into requirements, architecture updates, and operational CONOPS changes?",False,"What feedback loops are needed to connect DT&E resilience findings back into requirements, architecture updates, and operational CONOPS changes?",What,DomainTopic=Operational resilience; cyberattack-resilient systems; DT&E measurement | ScenarioType=Reference use case + measurement framework for DT&E | Hits=[],"What feedback loops are needed to connect DT&E resilience findings back into requirements, architecture updates, and operational CONOPS changes?",True
INSIGHT-2022-VTR-DE-ECOSYS,INSIGHT-2022-VTR-DE-ECOSYS-Q01,2022,INSIGHT (INCOSE),Magazine/Professional,The Versatile Test Reactor Open Digital Engineering Ecosystem,"Ritter, N.; et al.",Digital engineering ecosystem; nuclear test reactor program,Real program ecosystem example (VTR open DE),Digital thread/ecosystem design; open architecture; interoperability approach,DE ecosystem architecture; toolchain concepts,"What open digital engineering ecosystem elements (data standards, interfaces, repositories, governance) are required to support a complex program across its lifecycle?",Primary,Infrastructure & model reuse,Interoperability; Standard; Interface; Data; Governance; Artifact,,Model exchange success rate; integration time,Program example (reprinted),Low-Medium,Open (PDF),Unclassified,DE ecosystem architecture,Digital thread / ecosystem architecture,https://www.incose.org/docs/default-source/publication-products/insight/insight_vol_28_issue_1.pdf?sfvrsn=5e878bc5_4,"Ritter, N., et al. (2022). The Versatile Test Reactor Open Digital Engineering Ecosystem. INSIGHT (reprinted in Vol. 28, Issue 1, 2025). INCOSE.",[],False,"What open digital engineering ecosystem elements (data standards, interfaces, repositories, governance) are required to support a complex program across its lifecycle?",False,"What open digital engineering ecosystem elements (data standards, interfaces, repositories, governance) are required to support a complex program across its lifecycle?",What,DomainTopic=Digital engineering ecosystem; nuclear test reactor program | ScenarioType=Real program ecosystem example (VTR open DE) | Hits=[],"What open digital engineering ecosystem elements (data standards, interfaces, repositories, governance) are required to support a complex program across its lifecycle?",False
INSIGHT-2022-VTR-DE-ECOSYS,INSIGHT-2022-VTR-DE-ECOSYS-Q02,2022,INSIGHT (INCOSE),Magazine/Professional,The Versatile Test Reactor Open Digital Engineering Ecosystem,"Ritter, N.; et al.",Digital engineering ecosystem; nuclear test reactor program,Real program ecosystem example (VTR open DE),Digital thread/ecosystem design; open architecture; interoperability approach,DE ecosystem architecture; toolchain concepts,How should configuration management and baselining be handled across many tools so that safety-critical decisions remain traceable and auditable?,Primary,Baseline & configuration management,Baseline; Configuration; Traceability; Verification; Validation; Decision,,,Program example (reprinted),Low-Medium,Open (PDF),Unclassified,Configuration governance,CM + traceability framework,https://www.incose.org/docs/default-source/publication-products/insight/insight_vol_28_issue_1.pdf?sfvrsn=5e878bc5_4,"Ritter, N., et al. (2022). The Versatile Test Reactor Open Digital Engineering Ecosystem. INSIGHT (reprinted in Vol. 28, Issue 1, 2025). INCOSE.",[],False,How should configuration management and baselining be handled across many tools so that safety-critical decisions remain traceable and auditable?,False,How should configuration management and baselining be handled across many tools so that safety-critical decisions remain traceable and auditable?,How,DomainTopic=Digital engineering ecosystem; nuclear test reactor program | ScenarioType=Real program ecosystem example (VTR open DE) | Hits=[],How should configuration management and baselining be handled across many tools so that safety-critical decisions remain traceable and auditable?,False
INSIGHT-2022-VTR-DE-ECOSYS,INSIGHT-2022-VTR-DE-ECOSYS-Q03,2022,INSIGHT (INCOSE),Magazine/Professional,The Versatile Test Reactor Open Digital Engineering Ecosystem,"Ritter, N.; et al.",Digital engineering ecosystem; nuclear test reactor program,Real program ecosystem example (VTR open DE),Digital thread/ecosystem design; open architecture; interoperability approach,DE ecosystem architecture; toolchain concepts,"Which measures (schedule, cost, defect/rework, decision latency) best demonstrate value of the DE ecosystem to program leadership?",Secondary,SE practice effectiveness,Measure; Cost; Schedule; Decision; Value; Change,,,Program example (reprinted),Low-Medium,Open (PDF),Unclassified,Value demonstration / ROI,Metrics & benefits realization,https://www.incose.org/docs/default-source/publication-products/insight/insight_vol_28_issue_1.pdf?sfvrsn=5e878bc5_4,"Ritter, N., et al. (2022). The Versatile Test Reactor Open Digital Engineering Ecosystem. INSIGHT (reprinted in Vol. 28, Issue 1, 2025). INCOSE.",[],False,"Which measures (schedule, cost, defect/rework, decision latency) best demonstrate value of the DE ecosystem to program leadership?",False,"Which measures (schedule, cost, defect/rework, decision latency) best demonstrate value of the DE ecosystem to program leadership?",Which,DomainTopic=Digital engineering ecosystem; nuclear test reactor program | ScenarioType=Real program ecosystem example (VTR open DE) | Hits=[],"Which measures (schedule, cost, defect/rework, decision latency) best demonstrate value of the DE ecosystem to program leadership?",True
JDMS-2022-AI-C2-GAMES,JDMS-2022-AI-C2-GAMES-Q01,2022,Journal of Defense Modeling and Simulation,Journal,On games and simulators as a platform for development of artificial intelligence for command and control,"Goecks, V. G.; Waytowich, N.; Asher, D. E.; et al.",AI for C2; simulation platforms; multi-agent scenarios,Survey/position paper with military-parallel game/simulator scenarios,Comparative analysis of games/simulators; mapping to C2 research needs,Scenario characteristics; platform capability taxonomy,"Which properties of game/simulator environments (imperfect information, adversary behavior, resource constraints, tempo) best map to operational C2 problems and training objectives?",Primary,Infrastructure & model reuse,Scenario; Model; C2; Constraint; Resource; Abstraction; Validation,,,Literature synthesis + conceptual framing,High (conceptual; no proprietary data),Open (PDF via SAGE),Unclassified,Platform selection for C2 AI R&D,Simulation environment assessment,https://journals.sagepub.com/doi/pdf/10.1177/15485129221083278,"Goecks, V. G., Waytowich, N., Asher, D. E., et al. (2022). On games and simulators as a platform for development of artificial intelligence for command and control. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/15485129221083278",['C2'],True,"Which properties of game/simulator environments (imperfect information, adversary behavior, resource constraints, tempo) best map to operational command and control problems and training objectives?",True,"Which properties of game/simulator environments (imperfect information, adversary behavior, resource constraints, tempo) best map to operational command and control problems and training objectives?",Which,DomainTopic=AI for C2; simulation platforms; multi-agent scenarios | ScenarioType=Survey/position paper with military-parallel game/simulator scenarios | Hits=['C2'],"Which properties of game/simulator environments (imperfect information, adversary behavior, resource constraints, tempo) best map to operational C2 problems and training objectives?",False
JDMS-2022-AI-C2-GAMES,JDMS-2022-AI-C2-GAMES-Q02,2022,Journal of Defense Modeling and Simulation,Journal,On games and simulators as a platform for development of artificial intelligence for command and control,"Goecks, V. G.; Waytowich, N.; Asher, D. E.; et al.",AI for C2; simulation platforms; multi-agent scenarios,Survey/position paper with military-parallel game/simulator scenarios,Comparative analysis of games/simulators; mapping to C2 research needs,Scenario characteristics; platform capability taxonomy,"How should mission objectives, rules of engagement, and measures be encoded so that AI performance improvements translate to operationally meaningful gains rather than gaming the metrics?",Primary,Traceability & evidence management,Measure; Objective; Constraint; Validation; Verification; Stakeholder,Mission objective attainment; collateral limits,,Literature synthesis + conceptual framing,High (conceptual; no proprietary data),Open (PDF via SAGE),Unclassified,Metric/Objective definition,Evaluation framework,https://journals.sagepub.com/doi/pdf/10.1177/15485129221083278,"Goecks, V. G., Waytowich, N., Asher, D. E., et al. (2022). On games and simulators as a platform for development of artificial intelligence for command and control. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/15485129221083278",[],False,"How should mission objectives, rules of engagement, and measures be encoded so that AI performance improvements translate to operationally meaningful gains rather than gaming the metrics?",False,"How should mission objectives, rules of engagement, and measures be encoded so that AI performance improvements translate to operationally meaningful gains rather than gaming the metrics?",How,DomainTopic=AI for C2; simulation platforms; multi-agent scenarios | ScenarioType=Survey/position paper with military-parallel game/simulator scenarios | Hits=[],"How should mission objectives, rules of engagement, and measures be encoded so that AI performance improvements translate to operationally meaningful gains rather than gaming the metrics?",True
JDMS-2022-AI-C2-GAMES,JDMS-2022-AI-C2-GAMES-Q03,2022,Journal of Defense Modeling and Simulation,Journal,On games and simulators as a platform for development of artificial intelligence for command and control,"Goecks, V. G.; Waytowich, N.; Asher, D. E.; et al.",AI for C2; simulation platforms; multi-agent scenarios,Survey/position paper with military-parallel game/simulator scenarios,Comparative analysis of games/simulators; mapping to C2 research needs,Scenario characteristics; platform capability taxonomy,What human-in-the-loop interfaces and governance controls are needed to keep AI-enabled C2 experimentation safe and aligned with commander intent?,Secondary,Risk management & technical reviews,Governance; Risk; Decision; Stakeholder; Constraint; Verification,,,Literature synthesis + conceptual framing,High (conceptual; no proprietary data),Open (PDF via SAGE),Unclassified,Experiment governance,Human-in-the-loop + controls,https://journals.sagepub.com/doi/pdf/10.1177/15485129221083278,"Goecks, V. G., Waytowich, N., Asher, D. E., et al. (2022). On games and simulators as a platform for development of artificial intelligence for command and control. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/15485129221083278",['C2'],True,What human-in-the-loop interfaces and governance controls are needed to keep AI-enabled command and control experimentation safe and aligned with commander intent?,True,What human-in-the-loop interfaces and governance controls are needed to keep AI-enabled command and control experimentation safe and aligned with commander intent?,What,DomainTopic=AI for C2; simulation platforms; multi-agent scenarios | ScenarioType=Survey/position paper with military-parallel game/simulator scenarios | Hits=['C2'],What human-in-the-loop interfaces and governance controls are needed to keep AI-enabled C2 experimentation safe and aligned with commander intent?,True
SERC-2022-TR-001,SERC-2022-TR-001-Q01,2022,SERC Technical Report,Technical Report,Methods for Integrating Dynamic Requirements,Systems Engineering Research Center (SERC),Dynamic requirements; portfolio decision analysis; value modeling under uncertainty,"Multiple detailed case studies (technology platform, policy portfolio, STEM talent pipeline)",Decision analysis; multi-attribute utility; uncertainty/sensitivity analysis; portfolio modeling,Analytic framework; utility models; case-study portfolios; sensitivity results,"How should we adapt requirements and investment decisions over time when mission value, technology maturity, and external drivers change (and decisions must be revisited repeatedly)?",Primary,Evolution & lifecycle decision-making,Requirement; Change; Decision; Portfolio; Uncertainty; Tradeoff; Value,Mission value / utility over time,,Worked case studies in report,Medium (methods detailed; data partially illustrative),Open (PDF),Unclassified,Iterative portfolio/requirements update,Decision analysis (dynamic requirements),https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1644269285.SERC_ART005_A013_Final%20Technical%20Report.pdf,Systems Engineering Research Center (SERC). (2022). Methods for Integrating Dynamic Requirements (SERC-2022-TR-001).,[],False,"How should we adapt requirements and investment decisions over time when mission value, technology maturity, and external drivers change (and decisions must be revisited repeatedly)?",False,"How should we adapt requirements and investment decisions over time when mission value, technology maturity, and external drivers change (and decisions must be revisited repeatedly)?",How,"DomainTopic=Dynamic requirements; portfolio decision analysis; value modeling under uncertainty | ScenarioType=Multiple detailed case studies (technology platform, policy portfolio, STEM talent pipeline) | Hits=[]","How should we adapt requirements and investment decisions over time when mission value, technology maturity, and external drivers change (and decisions must be revisited repeatedly)?",False
SERC-2022-TR-001,SERC-2022-TR-001-Q02,2022,SERC Technical Report,Technical Report,Methods for Integrating Dynamic Requirements,Systems Engineering Research Center (SERC),Dynamic requirements; portfolio decision analysis; value modeling under uncertainty,"Multiple detailed case studies (technology platform, policy portfolio, STEM talent pipeline)",Decision analysis; multi-attribute utility; uncertainty/sensitivity analysis; portfolio modeling,Analytic framework; utility models; case-study portfolios; sensitivity results,"Which requirements are most sensitive to uncertainties (demand, costs, performance, policy constraints), and which design or policy levers stabilize mission outcomes?",Primary,"Uncertainty, sensitivity & decision robustness",Requirement; Uncertainty; Sensitivity; Tradeoff; Constraint; Decision,Utility robustness; regret,,Worked case studies in report,Medium (methods detailed; data partially illustrative),Open (PDF),Unclassified,Robust requirements set selection,Sensitivity analysis / robustness study,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1644269285.SERC_ART005_A013_Final%20Technical%20Report.pdf,Systems Engineering Research Center (SERC). (2022). Methods for Integrating Dynamic Requirements (SERC-2022-TR-001).,[],False,"Which requirements are most sensitive to uncertainties (demand, costs, performance, policy constraints), and which design or policy levers stabilize mission outcomes?",False,"Which requirements are most sensitive to uncertainties (demand, costs, performance, policy constraints), and which design or policy levers stabilize mission outcomes?",Which,"DomainTopic=Dynamic requirements; portfolio decision analysis; value modeling under uncertainty | ScenarioType=Multiple detailed case studies (technology platform, policy portfolio, STEM talent pipeline) | Hits=[]","Which requirements are most sensitive to uncertainties (demand, costs, performance, policy constraints), and which design or policy levers stabilize mission outcomes?",False
SERC-2022-TR-001,SERC-2022-TR-001-Q03,2022,SERC Technical Report,Technical Report,Methods for Integrating Dynamic Requirements,Systems Engineering Research Center (SERC),Dynamic requirements; portfolio decision analysis; value modeling under uncertainty,"Multiple detailed case studies (technology platform, policy portfolio, STEM talent pipeline)",Decision analysis; multi-attribute utility; uncertainty/sensitivity analysis; portfolio modeling,Analytic framework; utility models; case-study portfolios; sensitivity results,What minimal set of traceability and evidence artifacts is needed to justify requirement changes to stakeholders across updates (and prevent churn)?,Secondary,Traceability & evidence management,Traceability; Artifact; Stakeholder; Baseline; Change; Requirement,,Change request cycle time; review burden,Worked case studies in report,Medium (methods detailed; data partially illustrative),Open (PDF),Unclassified,Evidence strategy for change control,Traceability/evidence framework,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1644269285.SERC_ART005_A013_Final%20Technical%20Report.pdf,Systems Engineering Research Center (SERC). (2022). Methods for Integrating Dynamic Requirements (SERC-2022-TR-001).,[],False,What minimal set of traceability and evidence artifacts is needed to justify requirement changes to stakeholders across updates (and prevent churn)?,False,What minimal set of traceability and evidence artifacts is needed to justify requirement changes to stakeholders across updates (and prevent churn)?,What,"DomainTopic=Dynamic requirements; portfolio decision analysis; value modeling under uncertainty | ScenarioType=Multiple detailed case studies (technology platform, policy portfolio, STEM talent pipeline) | Hits=[]",What minimal set of traceability and evidence artifacts is needed to justify requirement changes to stakeholders across updates (and prevent churn)?,False
SERC-2022-TR-008,SERC-2022-TR-008-Q01,2022,SERC Technical Report,Technical Report,Digital Engineering Transformation at JPEO-CBRND (WRT-1052),"DeLaurentis, D.; Guariniello, C.; et al. (Purdue University, for SERC)",Digital engineering transformation; enterprise portfolio analysis; CBRN defense mission thread,Operational mission thread (unmounted reconnaissance and decontamination of chemically contaminated site) + portfolio/AM use cases,Agent-based modeling; MBSE mission-thread representation; portfolio decision framework; cost-benefit framing,ABM simulation; MBSE mission-thread model; decision framework for AM vs traditional manufacturing,"Across alternative CBRN mission-thread scenarios, which combinations of technologies and organizational actions maximize mission success while minimizing time-to-neutralize and logistical burden?",Primary,Operational planning under uncertainty,Mission; Scenario; Task; Resource; Tradeoff; Uncertainty; Decision,Mission success rate; time to decontaminate; casualties avoided,,Use-case driven modeling + lessons learned,Medium,Open (PDF),Unclassified,Portfolio selection for mission threads,ABM + MBSE mission-thread model,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1665428051.SERC_A013_WRT-1052_Final%20Technical%20Report.pdf,"DeLaurentis, D., Guariniello, C., et al. (2022). Digital Engineering Transformation at JPEO-CBRND (SERC-2022-TR-008). Systems Engineering Research Center.",[],False,"Across alternative CBRN mission-thread scenarios, which combinations of technologies and organizational actions maximize mission success while minimizing time-to-neutralize and logistical burden?",False,"How should across alternative CBRN mission-thread scenarios, which combinations of technologies and organizational actions maximize mission success while minimizing time-to-neutralize and logistical burden?",How,DomainTopic=Digital engineering transformation; enterprise portfolio analysis; CBRN defense mission thread | ScenarioType=Operational mission thread (unmounted reconnaissance and decontamination of chemically contaminated site) + portfolio/AM use cases | Hits=[],"Across alternative CBRN mission-thread scenarios, which combinations of technologies and organizational actions maximize mission success while minimizing time-to-neutralize and logistical burden?",True
SERC-2022-TR-008,SERC-2022-TR-008-Q02,2022,SERC Technical Report,Technical Report,Digital Engineering Transformation at JPEO-CBRND (WRT-1052),"DeLaurentis, D.; Guariniello, C.; et al. (Purdue University, for SERC)",Digital engineering transformation; enterprise portfolio analysis; CBRN defense mission thread,Operational mission thread (unmounted reconnaissance and decontamination of chemically contaminated site) + portfolio/AM use cases,Agent-based modeling; MBSE mission-thread representation; portfolio decision framework; cost-benefit framing,ABM simulation; MBSE mission-thread model; decision framework for AM vs traditional manufacturing,"What enterprise-level portfolio decision approach can compare disparate technologies when performance depends on scenario context (e.g., AM vs traditional manufacturing, deployment constraints, data/IP limits)?",Primary,Portfolio/architecture trade-space,Portfolio; Tradeoff; Cost; Constraint; Decision; Scenario; Value,Portfolio utility; cost-effectiveness,,Use-case driven modeling + lessons learned,Medium,Open (PDF),Unclassified,Enterprise portfolio prioritization,Decision framework / CBA,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1665428051.SERC_A013_WRT-1052_Final%20Technical%20Report.pdf,"DeLaurentis, D., Guariniello, C., et al. (2022). Digital Engineering Transformation at JPEO-CBRND (SERC-2022-TR-008). Systems Engineering Research Center.",[],False,"What enterprise-level portfolio decision approach can compare disparate technologies when performance depends on scenario context (e.g., AM vs traditional manufacturing, deployment constraints, data/IP limits)?",False,"What enterprise-level portfolio decision approach can compare disparate technologies when performance depends on scenario context (e.g., AM vs traditional manufacturing, deployment constraints, data/IP limits)?",What,DomainTopic=Digital engineering transformation; enterprise portfolio analysis; CBRN defense mission thread | ScenarioType=Operational mission thread (unmounted reconnaissance and decontamination of chemically contaminated site) + portfolio/AM use cases | Hits=[],"What enterprise-level portfolio decision approach can compare disparate technologies when performance depends on scenario context (e.g., AM vs traditional manufacturing, deployment constraints, data/IP limits)?",True
SERC-2022-TR-008,SERC-2022-TR-008-Q03,2022,SERC Technical Report,Technical Report,Digital Engineering Transformation at JPEO-CBRND (WRT-1052),"DeLaurentis, D.; Guariniello, C.; et al. (Purdue University, for SERC)",Digital engineering transformation; enterprise portfolio analysis; CBRN defense mission thread,Operational mission thread (unmounted reconnaissance and decontamination of chemically contaminated site) + portfolio/AM use cases,Agent-based modeling; MBSE mission-thread representation; portfolio decision framework; cost-benefit framing,ABM simulation; MBSE mission-thread model; decision framework for AM vs traditional manufacturing,"Which bottlenecks in the mission thread are most sensitive to comms/logistics constraints, and what model fidelity is needed to detect them reliably?",Secondary,"Drivers, bottlenecks & investment levers",Bottleneck; Dependency; Resource; Sensitivity; Scenario; Architecture,,Throughput; queue time; comms latency,Use-case driven modeling + lessons learned,Medium,Open (PDF),Unclassified,Focus areas for improvement,ABM sensitivity / bottleneck analysis,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1665428051.SERC_A013_WRT-1052_Final%20Technical%20Report.pdf,"DeLaurentis, D., Guariniello, C., et al. (2022). Digital Engineering Transformation at JPEO-CBRND (SERC-2022-TR-008). Systems Engineering Research Center.",[],False,"Which bottlenecks in the mission thread are most sensitive to comms/logistics constraints, and what model fidelity is needed to detect them reliably?",False,"Which bottlenecks in the mission thread are most sensitive to comms/logistics constraints, and what model fidelity is needed to detect them reliably?",Which,DomainTopic=Digital engineering transformation; enterprise portfolio analysis; CBRN defense mission thread | ScenarioType=Operational mission thread (unmounted reconnaissance and decontamination of chemically contaminated site) + portfolio/AM use cases | Hits=[],"Which bottlenecks in the mission thread are most sensitive to comms/logistics constraints, and what model fidelity is needed to detect them reliably?",False
DAU-DAMAG-2023-PORTFOLIO-FOCUS,DAU-DAMAG-2023-PORTFOLIO-FOCUS-Q01,2023,Defense Acquisition Magazine (DAU),Magazine/Trade,Portfolio-Focused Acquisition for the 21st Century Battlespace,"Tremper, D.",Portfolio acquisition; joint capability gaps; speed/scale,Policy/approach article with defense examples,Conceptual + governance framing; portfolio management argumentation,Conceptual model; governance recommendations,How should acquisition organizations define and govern mission portfolios so that investments align to joint operational gaps rather than isolated program outcomes?,Primary,Portfolio governance & review questions,Portfolio; Stakeholder; Decision; Capability; Value; Governance,,,Practice-oriented synthesis,High (conceptual),Open (web),Unclassified,Portfolio governance design,Governance/portfolio model,https://www.dau.edu/library/damag/july-august2023/portfolio-focused-acquisition,"Tremper, D. (2023). Portfolio-Focused Acquisition for the 21st Century Battlespace. Defense Acquisition Magazine (DAU).",[],False,How should acquisition organizations define and govern mission portfolios so that investments align to joint operational gaps rather than isolated program outcomes?,False,How should acquisition organizations define and govern mission portfolios so that investments align to joint operational gaps rather than isolated program outcomes?,How,DomainTopic=Portfolio acquisition; joint capability gaps; speed/scale | ScenarioType=Policy/approach article with defense examples | Hits=[],How should acquisition organizations define and govern mission portfolios so that investments align to joint operational gaps rather than isolated program outcomes?,False
DAU-DAMAG-2023-PORTFOLIO-FOCUS,DAU-DAMAG-2023-PORTFOLIO-FOCUS-Q02,2023,Defense Acquisition Magazine (DAU),Magazine/Trade,Portfolio-Focused Acquisition for the 21st Century Battlespace,"Tremper, D.",Portfolio acquisition; joint capability gaps; speed/scale,Policy/approach article with defense examples,Conceptual + governance framing; portfolio management argumentation,Conceptual model; governance recommendations,"Which metrics best demonstrate portfolio-level mission effects (integration, interoperability, and operational readiness) across heterogeneous programs?",Primary,Architecture & integration for mission effects,Measure; Architecture; Interoperability; Capability; Traceability; Decision,Portfolio mission-effect contribution,,Practice-oriented synthesis,High (conceptual),Open (web),Unclassified,Portfolio MoE definition,Metrics framework,https://www.dau.edu/library/damag/july-august2023/portfolio-focused-acquisition,"Tremper, D. (2023). Portfolio-Focused Acquisition for the 21st Century Battlespace. Defense Acquisition Magazine (DAU).",[],False,"Which metrics best demonstrate portfolio-level mission effects (integration, interoperability, and operational readiness) across heterogeneous programs?",False,"Which metrics best demonstrate portfolio-level mission effects (integration, interoperability, and operational readiness) across heterogeneous programs?",Which,DomainTopic=Portfolio acquisition; joint capability gaps; speed/scale | ScenarioType=Policy/approach article with defense examples | Hits=[],"Which metrics best demonstrate portfolio-level mission effects (integration, interoperability, and operational readiness) across heterogeneous programs?",False
DAU-DAMAG-2023-PORTFOLIO-FOCUS,DAU-DAMAG-2023-PORTFOLIO-FOCUS-Q03,2023,Defense Acquisition Magazine (DAU),Magazine/Trade,Portfolio-Focused Acquisition for the 21st Century Battlespace,"Tremper, D.",Portfolio acquisition; joint capability gaps; speed/scale,Policy/approach article with defense examples,Conceptual + governance framing; portfolio management argumentation,Conceptual model; governance recommendations,What review questions and artifacts should be standardized to accelerate cross-program decision-making (without reducing rigor)?,Secondary,Risk management & technical reviews,Artifact; Traceability; Governance; Decision; Baseline; Risk,,,Practice-oriented synthesis,High (conceptual),Open (web),Unclassified,Standard review template,Review governance,https://www.dau.edu/library/damag/july-august2023/portfolio-focused-acquisition,"Tremper, D. (2023). Portfolio-Focused Acquisition for the 21st Century Battlespace. Defense Acquisition Magazine (DAU).",[],False,What review questions and artifacts should be standardized to accelerate cross-program decision-making (without reducing rigor)?,False,What review questions and artifacts should be standardized to accelerate cross-program decision-making (without reducing rigor)?,What,DomainTopic=Portfolio acquisition; joint capability gaps; speed/scale | ScenarioType=Policy/approach article with defense examples | Hits=[],What review questions and artifacts should be standardized to accelerate cross-program decision-making (without reducing rigor)?,False
JDMS-2023-FOG-AFSIM,JDMS-2023-FOG-AFSIM-Q01,2023,Journal of Defense Modeling and Simulation,Journal,Modeling fog of war effects in AFSIM,"Tryhorn, D.; Dill, R.; Hodson, D. D.; Grimaila, M. R.; Myers, C. W.",C2; situational awareness; simulation of information uncertainty,C2 wargame/simulation scenario with fog manipulation,AFSIM simulation; cognitive decision models review; fog identification & manipulation method,AFSIM scenario; fog manipulation methodology; analysis results,How does uncertainty and degradation in sensor/communications information flow change commander decisions and overall mission outcomes in a C2 scenario?,Primary,Operational planning under uncertainty,Scenario; Uncertainty; C2; Decision; Threat; Measure; Simulation,Mission success; decision timeliness; SA quality,,Simulation-based study,Medium (scenario details partially in paper),Open (PDF via SAGE),Unclassified,COA robustness under information uncertainty,AFSIM simulation + fog manipulation,https://journals.sagepub.com/doi/pdf/10.1177/15485129211041963,"Tryhorn, D., Dill, R., Hodson, D. D., Grimaila, M. R., & Myers, C. W. (2023). Modeling fog of war effects in AFSIM. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/15485129211041963",['C2'],True,How does uncertainty and degradation in sensor/communications information flow change commander decisions and overall mission outcomes in a command and control scenario?,True,How does uncertainty and degradation in sensor/communications information flow change commander decisions and overall mission outcomes in a command and control scenario?,How,DomainTopic=C2; situational awareness; simulation of information uncertainty | ScenarioType=C2 wargame/simulation scenario with fog manipulation | Hits=['C2'],How does uncertainty and degradation in sensor/communications information flow change commander decisions and overall mission outcomes in a C2 scenario?,False
JDMS-2023-FOG-AFSIM,JDMS-2023-FOG-AFSIM-Q02,2023,Journal of Defense Modeling and Simulation,Journal,Modeling fog of war effects in AFSIM,"Tryhorn, D.; Dill, R.; Hodson, D. D.; Grimaila, M. R.; Myers, C. W.",C2; situational awareness; simulation of information uncertainty,C2 wargame/simulation scenario with fog manipulation,AFSIM simulation; cognitive decision models review; fog identification & manipulation method,AFSIM scenario; fog manipulation methodology; analysis results,Which information sources and link characteristics are the dominant drivers of 'fog' (and therefore the best candidates for investment or protection)?,Primary,"Drivers, bottlenecks & investment levers",Bottleneck; Dependency; Architecture; Resource; Sensitivity; Tradeoff,,Information latency; packet loss; sensor revisit,Simulation-based study,Medium (scenario details partially in paper),Open (PDF via SAGE),Unclassified,Sensor/comms investment prioritization,Sensitivity analysis on scenario elements,https://journals.sagepub.com/doi/pdf/10.1177/15485129211041963,"Tryhorn, D., Dill, R., Hodson, D. D., Grimaila, M. R., & Myers, C. W. (2023). Modeling fog of war effects in AFSIM. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/15485129211041963",[],False,Which information sources and link characteristics are the dominant drivers of 'fog' (and therefore the best candidates for investment or protection)?,False,Which information sources and link characteristics are the dominant drivers of 'fog' (and therefore the best candidates for investment or protection)?,Which,DomainTopic=C2; situational awareness; simulation of information uncertainty | ScenarioType=C2 wargame/simulation scenario with fog manipulation | Hits=[],Which information sources and link characteristics are the dominant drivers of 'fog' (and therefore the best candidates for investment or protection)?,False
JDMS-2023-FOG-AFSIM,JDMS-2023-FOG-AFSIM-Q03,2023,Journal of Defense Modeling and Simulation,Journal,Modeling fog of war effects in AFSIM,"Tryhorn, D.; Dill, R.; Hodson, D. D.; Grimaila, M. R.; Myers, C. W.",C2; situational awareness; simulation of information uncertainty,C2 wargame/simulation scenario with fog manipulation,AFSIM simulation; cognitive decision models review; fog identification & manipulation method,AFSIM scenario; fog manipulation methodology; analysis results,What scenario and model assumptions must be documented to ensure results can be reproduced and compared across studies or tool versions?,Secondary,Study design & validity,Assumption; Baseline; Configuration; Scenario; Traceability; Validation,,,Simulation-based study,Medium (scenario details partially in paper),Open (PDF via SAGE),Unclassified,Experiment documentation standard,Experiment design / provenance,https://journals.sagepub.com/doi/pdf/10.1177/15485129211041963,"Tryhorn, D., Dill, R., Hodson, D. D., Grimaila, M. R., & Myers, C. W. (2023). Modeling fog of war effects in AFSIM. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/15485129211041963",[],False,What scenario and model assumptions must be documented to ensure results can be reproduced and compared across studies or tool versions?,False,What scenario and model assumptions must be documented to ensure results can be reproduced and compared across studies or tool versions?,What,DomainTopic=C2; situational awareness; simulation of information uncertainty | ScenarioType=C2 wargame/simulation scenario with fog manipulation | Hits=[],What scenario and model assumptions must be documented to ensure results can be reproduced and compared across studies or tool versions?,False
JDMS-2023-LVC-LOOKBACK,JDMS-2023-LVC-LOOKBACK-Q01,2023,Journal of Defense Modeling and Simulation,Journal,A look back at the past 44 years of live virtual and constructive (LVC) training systems,(See paper for full author list),LVC training; mission rehearsal; test/training/ops convergence,Historical/industrial case review of LVC systems,Historical review; synthesis of LVC evolution and implications,System evolution narrative; capability comparisons,"What gaps remain between training/mission rehearsal/test environments and real operations, and which architectural choices reduce that gap for emerging technologies?",Primary,Gap analysis & modernization options,Architecture; Capability; Change; Interoperability; Validation; Test,,,Historical review,High (narrative synthesis),Open (PDF via SAGE),Unclassified,LVC modernization roadmap,Historical synthesis / capability roadmap,https://journals.sagepub.com/doi/pdf/10.1177/15485129221109574,(2023). A look back at the past 44 years of live virtual and constructive (LVC) training systems. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/15485129221109574,[],False,"What gaps remain between training/mission rehearsal/test environments and real operations, and which architectural choices reduce that gap for emerging technologies?",False,"What gaps remain between training/mission rehearsal/test environments and real operations, and which architectural choices reduce that gap for emerging technologies?",What,DomainTopic=LVC training; mission rehearsal; test/training/ops convergence | ScenarioType=Historical/industrial case review of LVC systems | Hits=[],"What gaps remain between training/mission rehearsal/test environments and real operations, and which architectural choices reduce that gap for emerging technologies?",False
JDMS-2023-LVC-LOOKBACK,JDMS-2023-LVC-LOOKBACK-Q02,2023,Journal of Defense Modeling and Simulation,Journal,A look back at the past 44 years of live virtual and constructive (LVC) training systems,(See paper for full author list),LVC training; mission rehearsal; test/training/ops convergence,Historical/industrial case review of LVC systems,Historical review; synthesis of LVC evolution and implications,System evolution narrative; capability comparisons,"How should we design LVC ecosystems so they can rapidly incorporate new AI-enabled systems, swarms, and directed-energy systems while maintaining safety and fidelity?",Primary,Infrastructure & model reuse,Interoperability; Standard; Configuration; Model; Test; Risk,,,Historical review,High (narrative synthesis),Open (PDF via SAGE),Unclassified,Ecosystem architecture selection,System-of-systems design,https://journals.sagepub.com/doi/pdf/10.1177/15485129221109574,(2023). A look back at the past 44 years of live virtual and constructive (LVC) training systems. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/15485129221109574,[],False,"How should we design LVC ecosystems so they can rapidly incorporate new AI-enabled systems, swarms, and directed-energy systems while maintaining safety and fidelity?",False,"How should we design LVC ecosystems so they can rapidly incorporate new AI-enabled systems, swarms, and directed-energy systems while maintaining safety and fidelity?",How,DomainTopic=LVC training; mission rehearsal; test/training/ops convergence | ScenarioType=Historical/industrial case review of LVC systems | Hits=[],"How should we design LVC ecosystems so they can rapidly incorporate new AI-enabled systems, swarms, and directed-energy systems while maintaining safety and fidelity?",True
JDMS-2023-LVC-LOOKBACK,JDMS-2023-LVC-LOOKBACK-Q03,2023,Journal of Defense Modeling and Simulation,Journal,A look back at the past 44 years of live virtual and constructive (LVC) training systems,(See paper for full author list),LVC training; mission rehearsal; test/training/ops convergence,Historical/industrial case review of LVC systems,Historical review; synthesis of LVC evolution and implications,System evolution narrative; capability comparisons,What evaluation measures and data collection practices allow LVC events to provide evidence usable for acquisition decisions (not just training feedback)?,Secondary,Traceability & evidence management,Evidence; Measure; Traceability; Decision; Validation; Artifact,,,Historical review,High (narrative synthesis),Open (PDF via SAGE),Unclassified,Evidence capture strategy,Instrumentation / data strategy,https://journals.sagepub.com/doi/pdf/10.1177/15485129221109574,(2023). A look back at the past 44 years of live virtual and constructive (LVC) training systems. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/15485129221109574,[],False,What evaluation measures and data collection practices allow LVC events to provide evidence usable for acquisition decisions (not just training feedback)?,False,What evaluation measures and data collection practices allow LVC events to provide evidence usable for acquisition decisions (not just training feedback)?,What,DomainTopic=LVC training; mission rehearsal; test/training/ops convergence | ScenarioType=Historical/industrial case review of LVC systems | Hits=[],What evaluation measures and data collection practices allow LVC events to provide evidence usable for acquisition decisions (not just training feedback)?,True
JDMS-2023-MISSION-ASSURANCE-MS,JDMS-2023-MISSION-ASSURANCE-MS-Q01,2023,Journal of Defense Modeling and Simulation,Journal,Modeling and simulation in mission assurance,"Trias, E.",Mission assurance; critical infrastructure; COOP/contingency planning,Operational environment modeling for cyber + physical infrastructure,M&S integration; scenario-based analysis for COOP and contingency planning,Integrated operational models; scenario comparisons; training/exercise insights,How can integrated models (cyber + physical + supporting infrastructure) be constructed to evaluate mission assurance and continuity of operations under disruptive events?,Primary,Risk mitigation & resilience,Risk; Threat; Scenario; Resilience; Dependency; Architecture; Simulation,Service continuity; mission downtime; recovery time,,Concept + examples,Medium,Open (PDF via SAGE),Unclassified,COOP design / mission assurance assessment,Integrated M&S for mission assurance,https://journals.sagepub.com/doi/pdf/10.1177/15485129221105084,"Trias, E. (2023). Modeling and simulation in mission assurance. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/15485129221105084",[],False,How can integrated models (cyber + physical + supporting infrastructure) be constructed to evaluate mission assurance and continuity of operations under disruptive events?,False,How can integrated models (cyber + physical + supporting infrastructure) be constructed to evaluate mission assurance and continuity of operations under disruptive events?,How,DomainTopic=Mission assurance; critical infrastructure; COOP/contingency planning | ScenarioType=Operational environment modeling for cyber + physical infrastructure | Hits=[],How can integrated models (cyber + physical + supporting infrastructure) be constructed to evaluate mission assurance and continuity of operations under disruptive events?,False
JDMS-2023-MISSION-ASSURANCE-MS,JDMS-2023-MISSION-ASSURANCE-MS-Q02,2023,Journal of Defense Modeling and Simulation,Journal,Modeling and simulation in mission assurance,"Trias, E.",Mission assurance; critical infrastructure; COOP/contingency planning,Operational environment modeling for cyber + physical infrastructure,M&S integration; scenario-based analysis for COOP and contingency planning,Integrated operational models; scenario comparisons; training/exercise insights,"Which contingency options and investments (hardening, redundancy, procedures) measurably improve resilience under plausible event sets?",Primary,Tradeoffs & decision robustness,Tradeoff; Cost; DesignChange; Scenario; Decision; Resilience,,,Concept + examples,Medium,Open (PDF via SAGE),Unclassified,Resilience investment selection,Scenario comparison / trade-space,https://journals.sagepub.com/doi/pdf/10.1177/15485129221105084,"Trias, E. (2023). Modeling and simulation in mission assurance. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/15485129221105084",[],False,"Which contingency options and investments (hardening, redundancy, procedures) measurably improve resilience under plausible event sets?",False,"Which contingency options and investments (hardening, redundancy, procedures) measurably improve resilience under plausible event sets?",Which,DomainTopic=Mission assurance; critical infrastructure; COOP/contingency planning | ScenarioType=Operational environment modeling for cyber + physical infrastructure | Hits=[],"Which contingency options and investments (hardening, redundancy, procedures) measurably improve resilience under plausible event sets?",False
JDMS-2023-MISSION-ASSURANCE-MS,JDMS-2023-MISSION-ASSURANCE-MS-Q03,2023,Journal of Defense Modeling and Simulation,Journal,Modeling and simulation in mission assurance,"Trias, E.",Mission assurance; critical infrastructure; COOP/contingency planning,Operational environment modeling for cyber + physical infrastructure,M&S integration; scenario-based analysis for COOP and contingency planning,Integrated operational models; scenario comparisons; training/exercise insights,What evidence from training/exercises should be captured to validate the models and calibrate assumptions over time?,Secondary,"Test, evaluation & feedback",Validation; Evidence; Assumption; Test; Traceability; Change,,,Concept + examples,Medium,Open (PDF via SAGE),Unclassified,Model validation plan,Calibration / V&V,https://journals.sagepub.com/doi/pdf/10.1177/15485129221105084,"Trias, E. (2023). Modeling and simulation in mission assurance. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/15485129221105084",[],False,What evidence from training/exercises should be captured to validate the models and calibrate assumptions over time?,False,What evidence from training/exercises should be captured to validate the models and calibrate assumptions over time?,What,DomainTopic=Mission assurance; critical infrastructure; COOP/contingency planning | ScenarioType=Operational environment modeling for cyber + physical infrastructure | Hits=[],What evidence from training/exercises should be captured to validate the models and calibrate assumptions over time?,False
SERC-2023-TR-007,SERC-2023-TR-007-Q01,2023,SERC Technical Report,Technical Report,DAU Digital Engineering Simulation (Option Year 1) (WRT-1043),Systems Engineering Research Center (SERC),Digital engineering training simulation; model reuse; DE environment models,Training environment with multiple example models (Firebird/Bulldog/Silverfish etc.),SysML/MBSE model development; instructional design; simulation training environment,Reference SysML models; DE environment model; training scenarios and knowledge checks,Which reusable model elements and profiles best support rapid composition of credible mission engineering training scenarios (without breaking semantic consistency)?,Primary,Infrastructure & model reuse,Model; Artifact; Standard; Traceability; Interoperability; Baseline,,Reuse rate; model integration time,Delivered models + training environment description,Medium (models described; artifacts partly external),Open (PDF),Unclassified,Model library / profile selection,MBSE model reuse / profile strategy,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1683662859.SERC_WRT-1043_A013_Final%20Technical%20Report_OY1.pdf,Systems Engineering Research Center (SERC). (2023). DAU Digital Engineering Simulation (Option Year 1) (SERC-2023-TR-007).,[],False,Which reusable model elements and profiles best support rapid composition of credible mission engineering training scenarios (without breaking semantic consistency)?,False,Which reusable model elements and profiles best support rapid composition of credible mission engineering training scenarios (without breaking semantic consistency)?,Which,DomainTopic=Digital engineering training simulation; model reuse; DE environment models | ScenarioType=Training environment with multiple example models (Firebird/Bulldog/Silverfish etc.) | Hits=[],Which reusable model elements and profiles best support rapid composition of credible mission engineering training scenarios (without breaking semantic consistency)?,False
SERC-2023-TR-007,SERC-2023-TR-007-Q02,2023,SERC Technical Report,Technical Report,DAU Digital Engineering Simulation (Option Year 1) (WRT-1043),Systems Engineering Research Center (SERC),Digital engineering training simulation; model reuse; DE environment models,Training environment with multiple example models (Firebird/Bulldog/Silverfish etc.),SysML/MBSE model development; instructional design; simulation training environment,Reference SysML models; DE environment model; training scenarios and knowledge checks,"How should the DE environment (toolchain, repositories, configuration rules) be modeled so that learners can practice governance actions that mirror real programs?",Primary,Baseline & configuration management,Baseline; Configuration; Decision; Artifact; Standard; Traceability,,,Delivered models + training environment description,Medium (models described; artifacts partly external),Open (PDF),Unclassified,DE environment governance design,Configuration management model,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1683662859.SERC_WRT-1043_A013_Final%20Technical%20Report_OY1.pdf,Systems Engineering Research Center (SERC). (2023). DAU Digital Engineering Simulation (Option Year 1) (SERC-2023-TR-007).,[],False,"How should the DE environment (toolchain, repositories, configuration rules) be modeled so that learners can practice governance actions that mirror real programs?",False,"How should the DE environment (toolchain, repositories, configuration rules) be modeled so that learners can practice governance actions that mirror real programs?",How,DomainTopic=Digital engineering training simulation; model reuse; DE environment models | ScenarioType=Training environment with multiple example models (Firebird/Bulldog/Silverfish etc.) | Hits=[],"How should the DE environment (toolchain, repositories, configuration rules) be modeled so that learners can practice governance actions that mirror real programs?",True
SERC-2023-TR-007,SERC-2023-TR-007-Q03,2023,SERC Technical Report,Technical Report,DAU Digital Engineering Simulation (Option Year 1) (WRT-1043),Systems Engineering Research Center (SERC),Digital engineering training simulation; model reuse; DE environment models,Training environment with multiple example models (Firebird/Bulldog/Silverfish etc.),SysML/MBSE model development; instructional design; simulation training environment,Reference SysML models; DE environment model; training scenarios and knowledge checks,"What are the minimum verification and validation checks (consistency, completeness, interface sanity) that should be embedded as knowledge checks in a training environment?",Secondary,Study design & validity,Verification; Validation; Model; Constraint; Traceability; Test,,,Delivered models + training environment description,Medium (models described; artifacts partly external),Open (PDF),Unclassified,V&V rubric definition,Quality gates / rubric,https://sercproddata.s3.us-east-2.amazonaws.com/technical_reports/reports/1683662859.SERC_WRT-1043_A013_Final%20Technical%20Report_OY1.pdf,Systems Engineering Research Center (SERC). (2023). DAU Digital Engineering Simulation (Option Year 1) (SERC-2023-TR-007).,[],False,"What are the minimum verification and validation checks (consistency, completeness, interface sanity) that should be embedded as knowledge checks in a training environment?",False,"What are the minimum verification and validation checks (consistency, completeness, interface sanity) that should be embedded as knowledge checks in a training environment?",What,DomainTopic=Digital engineering training simulation; model reuse; DE environment models | ScenarioType=Training environment with multiple example models (Firebird/Bulldog/Silverfish etc.) | Hits=[],"What are the minimum verification and validation checks (consistency, completeness, interface sanity) that should be embedded as knowledge checks in a training environment?",False
DAU-DAMAG-2024-RISK-ACCEPT,DAU-DAMAG-2024-RISK-ACCEPT-Q01,2024,Defense Acquisition Magazine (DAU),Magazine/Trade,Department of the Air Force Streamlines Risk Acceptance and ... (Tiger Team case study),"Harris, (see DAU article PDF)",Airworthiness/risk acceptance governance; process streamlining,Tiger Team process-improvement case study,Process mapping; root-cause analysis; governance redesign,Revised risk acceptance construct; process changes,"How should risk assessment, acceptance, and approval be aligned to the operational chain of command to enable faster, risk-based decisions (without duplicative processes)?",Primary,Risk management & technical reviews,Governance; Risk; Decision; Stakeholder; Policy; Constraint,Time to risk decision; operational safety,,Case study narrative,Low-Medium,Open (web),Unclassified,Risk governance redesign,Process redesign / governance,https://www.dau.edu/library/damag/november-december2024/deptofairforce,Harris. (2024). Department of the Air Force Streamlines Risk Acceptance and ... (Tiger Team case study). Defense Acquisition Magazine (DAU).,[],False,"How should risk assessment, acceptance, and approval be aligned to the operational chain of command to enable faster, risk-based decisions (without duplicative processes)?",False,"How should risk assessment, acceptance, and approval be aligned to the operational chain of command to enable faster, risk-based decisions (without duplicative processes)?",How,DomainTopic=Airworthiness/risk acceptance governance; process streamlining | ScenarioType=Tiger Team process-improvement case study | Hits=[],"How should risk assessment, acceptance, and approval be aligned to the operational chain of command to enable faster, risk-based decisions (without duplicative processes)?",False
DAU-DAMAG-2024-RISK-ACCEPT,DAU-DAMAG-2024-RISK-ACCEPT-Q02,2024,Defense Acquisition Magazine (DAU),Magazine/Trade,Department of the Air Force Streamlines Risk Acceptance and ... (Tiger Team case study),"Harris, (see DAU article PDF)",Airworthiness/risk acceptance governance; process streamlining,Tiger Team process-improvement case study,Process mapping; root-cause analysis; governance redesign,Revised risk acceptance construct; process changes,"What process 'as-is' barriers and root causes most commonly create delays in risk acceptance for operational activities, and how should they be measured?",Primary,"Drivers, bottlenecks & investment levers",Bottleneck; Process; Measure; Baseline; Change; Schedule,,,Case study narrative,Low-Medium,Open (web),Unclassified,Process improvement priorities,Process analysis,https://www.dau.edu/library/damag/november-december2024/deptofairforce,Harris. (2024). Department of the Air Force Streamlines Risk Acceptance and ... (Tiger Team case study). Defense Acquisition Magazine (DAU).,[],False,"What process 'as-is' barriers and root causes most commonly create delays in risk acceptance for operational activities, and how should they be measured?",False,"What process 'as-is' barriers and root causes most commonly create delays in risk acceptance for operational activities, and how should they be measured?",What,DomainTopic=Airworthiness/risk acceptance governance; process streamlining | ScenarioType=Tiger Team process-improvement case study | Hits=[],"What process 'as-is' barriers and root causes most commonly create delays in risk acceptance for operational activities, and how should they be measured?",False
DAU-DAMAG-2024-RISK-ACCEPT,DAU-DAMAG-2024-RISK-ACCEPT-Q03,2024,Defense Acquisition Magazine (DAU),Magazine/Trade,Department of the Air Force Streamlines Risk Acceptance and ... (Tiger Team case study),"Harris, (see DAU article PDF)",Airworthiness/risk acceptance governance; process streamlining,Tiger Team process-improvement case study,Process mapping; root-cause analysis; governance redesign,Revised risk acceptance construct; process changes,"What artifacts and data (FAA certs, hazard analyses, operational categorizations) are required as evidence for the new tailorable construct?",Secondary,Traceability & evidence management,Evidence; Artifact; Validation; Verification; Policy; Traceability,,,Case study narrative,Low-Medium,Open (web),Unclassified,Evidence requirements definition,Evidence schema,https://www.dau.edu/library/damag/november-december2024/deptofairforce,Harris. (2024). Department of the Air Force Streamlines Risk Acceptance and ... (Tiger Team case study). Defense Acquisition Magazine (DAU).,[],False,"What artifacts and data (FAA certs, hazard analyses, operational categorizations) are required as evidence for the new tailorable construct?",False,"What artifacts and data (FAA certs, hazard analyses, operational categorizations) are required as evidence for the new tailorable construct?",What,DomainTopic=Airworthiness/risk acceptance governance; process streamlining | ScenarioType=Tiger Team process-improvement case study | Hits=[],"What artifacts and data (FAA certs, hazard analyses, operational categorizations) are required as evidence for the new tailorable construct?",True
DAU-DAMAG-2025-DIU-REMOTE,DAU-DAMAG-2025-DIU-REMOTE-Q01,2025,Defense Acquisition Magazine (DAU),Magazine/Trade,CASE STUDY: Remote Sensing (DIU Space Portfolio),"Varghese, A. J. (and/or DIU team)",Commercial space; remote sensing; portfolio transition to operational capability,"Real portfolio/company examples (e.g., commercial SAR/EO providers)",Portfolio transition analysis; scaling pathways; integration considerations,Portfolio examples; transition pathway narrative,"What is the most effective pathway to transition commercial remote-sensing capability into sustained operational use (contracting, integration, CONOPS, and authorities)?",Primary,Gap analysis & modernization options,Capability; CONOPS; Interoperability; Decision; Constraint; Stakeholder,Coverage; revisit rate; time-to-access data,,Case examples within magazine issue,Low-Medium,Open (PDF),Unclassified,Transition strategy selection,Portfolio transition case narrative,https://www.dau.edu/sites/default/files/2025-02/DIU_MarApr2025.pdf,"Varghese, A. J. (2025). CASE STUDY: Remote Sensing (DIU Space Portfolio). Defense Acquisition Magazine (DAU).",[],False,"What is the most effective pathway to transition commercial remote-sensing capability into sustained operational use (contracting, integration, CONOPS, and authorities)?",False,"What is the most effective pathway to transition commercial remote-sensing capability into sustained operational use (contracting, integration, CONOPS, and authorities)?",What,"DomainTopic=Commercial space; remote sensing; portfolio transition to operational capability | ScenarioType=Real portfolio/company examples (e.g., commercial SAR/EO providers) | Hits=[]","What is the most effective pathway to transition commercial remote-sensing capability into sustained operational use (contracting, integration, CONOPS, and authorities)?",True
DAU-DAMAG-2025-DIU-REMOTE,DAU-DAMAG-2025-DIU-REMOTE-Q02,2025,Defense Acquisition Magazine (DAU),Magazine/Trade,CASE STUDY: Remote Sensing (DIU Space Portfolio),"Varghese, A. J. (and/or DIU team)",Commercial space; remote sensing; portfolio transition to operational capability,"Real portfolio/company examples (e.g., commercial SAR/EO providers)",Portfolio transition analysis; scaling pathways; integration considerations,Portfolio examples; transition pathway narrative,"How should a portfolio manager compare multiple commercial providers when mission value depends on latency, security, tasking flexibility, and integration cost?",Primary,Portfolio governance & review questions,Portfolio; Tradeoff; Cost; Risk; Decision; Measure,,,Case examples within magazine issue,Low-Medium,Open (PDF),Unclassified,Provider selection / portfolio mix,Multi-criteria evaluation,https://www.dau.edu/sites/default/files/2025-02/DIU_MarApr2025.pdf,"Varghese, A. J. (2025). CASE STUDY: Remote Sensing (DIU Space Portfolio). Defense Acquisition Magazine (DAU).",[],False,"How should a portfolio manager compare multiple commercial providers when mission value depends on latency, security, tasking flexibility, and integration cost?",False,"How should a portfolio manager compare multiple commercial providers when mission value depends on latency, security, tasking flexibility, and integration cost?",How,"DomainTopic=Commercial space; remote sensing; portfolio transition to operational capability | ScenarioType=Real portfolio/company examples (e.g., commercial SAR/EO providers) | Hits=[]","How should a portfolio manager compare multiple commercial providers when mission value depends on latency, security, tasking flexibility, and integration cost?",False
DAU-DAMAG-2025-DIU-REMOTE,DAU-DAMAG-2025-DIU-REMOTE-Q03,2025,Defense Acquisition Magazine (DAU),Magazine/Trade,CASE STUDY: Remote Sensing (DIU Space Portfolio),"Varghese, A. J. (and/or DIU team)",Commercial space; remote sensing; portfolio transition to operational capability,"Real portfolio/company examples (e.g., commercial SAR/EO providers)",Portfolio transition analysis; scaling pathways; integration considerations,Portfolio examples; transition pathway narrative,"Which data standards, interfaces, and assurance controls are required to integrate commercial imagery products into C2/ISR enterprise workflows?",Secondary,Interoperability & integration,Interface; Standard; Data; Security; Verification; Architecture,,,Case examples within magazine issue,Low-Medium,Open (PDF),Unclassified,Integration architecture,Enterprise integration design,https://www.dau.edu/sites/default/files/2025-02/DIU_MarApr2025.pdf,"Varghese, A. J. (2025). CASE STUDY: Remote Sensing (DIU Space Portfolio). Defense Acquisition Magazine (DAU).","['C2', 'ISR']",True,"Which data standards, interfaces, and assurance controls are required to integrate commercial imagery products into command and control/sensing and reconnaissance enterprise workflows?",True,"Which data standards, interfaces, and assurance controls are required to integrate commercial imagery products into command and control/sensing and reconnaissance enterprise workflows?",Which,"DomainTopic=Commercial space; remote sensing; portfolio transition to operational capability | ScenarioType=Real portfolio/company examples (e.g., commercial SAR/EO providers) | Hits=['C2', 'ISR']","Which data standards, interfaces, and assurance controls are required to integrate commercial imagery products into C2/ISR enterprise workflows?",False
DAU-DAMAG-2025-RAPID-sUSV,DAU-DAMAG-2025-RAPID-sUSV-Q01,2025,Defense Acquisition Magazine (DAU),Magazine/Trade,A Case Study in Rapid sUSV Acquisition,"Cawley, M.",Rapid acquisition; unmanned surface vehicle; urgent needs,Real acquisition case narrative,Acquisition pathway discussion; obstacle removal; rapid procurement mechanisms,Timeline/process narrative; decisions and tradeoffs,"In an urgent operational need, which acquisition levers (authorities, contracting, prototyping) most reduce delivery time without unacceptable mission risk?",Primary,Schedule & developmental risk,Schedule; Risk; Decision; Constraint; Tradeoff; Stakeholder,Time-to-operational capability,,Case study narrative,Low-Medium,Open (web),Unclassified,Rapid acquisition strategy,Acquisition process analysis,https://www.dau.edu/library/damag/may-june2025/innovation-overcoming-obstacles,"Cawley, M. (2025). A Case Study in Rapid sUSV Acquisition. Defense Acquisition Magazine (DAU).",[],False,"In an urgent operational need, which acquisition levers (authorities, contracting, prototyping) most reduce delivery time without unacceptable mission risk?",False,"In an urgent operational need, which acquisition levers (authorities, contracting, prototyping) most reduce delivery time without unacceptable mission risk?",How,DomainTopic=Rapid acquisition; unmanned surface vehicle; urgent needs | ScenarioType=Real acquisition case narrative | Hits=[],"In an urgent operational need, which acquisition levers (authorities, contracting, prototyping) most reduce delivery time without unacceptable mission risk?",False
DAU-DAMAG-2025-RAPID-sUSV,DAU-DAMAG-2025-RAPID-sUSV-Q02,2025,Defense Acquisition Magazine (DAU),Magazine/Trade,A Case Study in Rapid sUSV Acquisition,"Cawley, M.",Rapid acquisition; unmanned surface vehicle; urgent needs,Real acquisition case narrative,Acquisition pathway discussion; obstacle removal; rapid procurement mechanisms,Timeline/process narrative; decisions and tradeoffs,How should capability requirements be scoped to enable rapid fielding while preserving upgrade paths and interoperability for follow-on increments?,Primary,Drivers & upgrade levers,Requirement; Upgrade; Interoperability; Baseline; Change; Capability,,,Case study narrative,Low-Medium,Open (web),Unclassified,Increment planning / roadmap,Incremental roadmap,https://www.dau.edu/library/damag/may-june2025/innovation-overcoming-obstacles,"Cawley, M. (2025). A Case Study in Rapid sUSV Acquisition. Defense Acquisition Magazine (DAU).",[],False,How should capability requirements be scoped to enable rapid fielding while preserving upgrade paths and interoperability for follow-on increments?,False,How should capability requirements be scoped to enable rapid fielding while preserving upgrade paths and interoperability for follow-on increments?,How,DomainTopic=Rapid acquisition; unmanned surface vehicle; urgent needs | ScenarioType=Real acquisition case narrative | Hits=[],How should capability requirements be scoped to enable rapid fielding while preserving upgrade paths and interoperability for follow-on increments?,False
DAU-DAMAG-2025-RAPID-sUSV,DAU-DAMAG-2025-RAPID-sUSV-Q03,2025,Defense Acquisition Magazine (DAU),Magazine/Trade,A Case Study in Rapid sUSV Acquisition,"Cawley, M.",Rapid acquisition; unmanned surface vehicle; urgent needs,Real acquisition case narrative,Acquisition pathway discussion; obstacle removal; rapid procurement mechanisms,Timeline/process narrative; decisions and tradeoffs,What evidence from early operational use should drive design changes and the transition from prototype to program of record?,Secondary,"Test, evaluation & feedback",Test; Validation; Evidence; DesignChange; Change; Decision,,,Case study narrative,Low-Medium,Open (web),Unclassified,Transition decision criteria,Operational feedback loop,https://www.dau.edu/library/damag/may-june2025/innovation-overcoming-obstacles,"Cawley, M. (2025). A Case Study in Rapid sUSV Acquisition. Defense Acquisition Magazine (DAU).",[],False,What evidence from early operational use should drive design changes and the transition from prototype to program of record?,False,What evidence from early operational use should drive design changes and the transition from prototype to program of record?,What,DomainTopic=Rapid acquisition; unmanned surface vehicle; urgent needs | ScenarioType=Real acquisition case narrative | Hits=[],What evidence from early operational use should drive design changes and the transition from prototype to program of record?,False
DAU-DAMAG-2025-SATCOM-SW,DAU-DAMAG-2025-SATCOM-SW-Q01,2025,Defense Acquisition Magazine (DAU),Magazine/Trade,The Future of Space Force Software Acquisitions—A Case Study in Satellite Communications,"Barasha, L. S.; Jung, S.; Chong, C. K.",Software acquisition; satcom mission planning; USSF digital service,Real program example (Evolved Strategic SATCOM mission planning software acquisition),Acquisition strategy narrative; process lessons; stakeholder engagement patterns,Acquisition approach; process steps; lessons learned,"How should a space mission planning software effort balance speed, security, and sustainment while aligning stakeholders across operators, acquisition, and cyber authorities?",Primary,Schedule & developmental risk,Schedule; Risk; Stakeholder; Constraint; Decision; Requirement,Time-to-field; mission availability,,Program case study narrative,Low-Medium (narrative; limited data),Open (web),Unclassified,Acquisition pathway selection,Program case narrative,https://www.dau.edu/library/damag/future-space-force-software,"Barasha, L. S., Jung, S., & Chong, C. K. (2025). The Future of Space Force Software Acquisitions—A Case Study in Satellite Communications. Defense Acquisition Magazine (DAU).",[],False,"How should a space mission planning software effort balance speed, security, and sustainment while aligning stakeholders across operators, acquisition, and cyber authorities?",False,"How should a space mission planning software effort balance speed, security, and sustainment while aligning stakeholders across operators, acquisition, and cyber authorities?",How,DomainTopic=Software acquisition; satcom mission planning; USSF digital service | ScenarioType=Real program example (Evolved Strategic SATCOM mission planning software acquisition) | Hits=[],"How should a space mission planning software effort balance speed, security, and sustainment while aligning stakeholders across operators, acquisition, and cyber authorities?",False
DAU-DAMAG-2025-SATCOM-SW,DAU-DAMAG-2025-SATCOM-SW-Q02,2025,Defense Acquisition Magazine (DAU),Magazine/Trade,The Future of Space Force Software Acquisitions—A Case Study in Satellite Communications,"Barasha, L. S.; Jung, S.; Chong, C. K.",Software acquisition; satcom mission planning; USSF digital service,Real program example (Evolved Strategic SATCOM mission planning software acquisition),Acquisition strategy narrative; process lessons; stakeholder engagement patterns,Acquisition approach; process steps; lessons learned,"What minimum set of requirements, interfaces, and evidence artifacts enables rapid iteration without losing traceability in a mission-critical environment?",Primary,Traceability & evidence management,Requirement; Interface; Traceability; Artifact; Verification; Baseline,,,Program case study narrative,Low-Medium (narrative; limited data),Open (web),Unclassified,Evidence/traceability strategy,Lean requirements governance,https://www.dau.edu/library/damag/future-space-force-software,"Barasha, L. S., Jung, S., & Chong, C. K. (2025). The Future of Space Force Software Acquisitions—A Case Study in Satellite Communications. Defense Acquisition Magazine (DAU).",[],False,"What minimum set of requirements, interfaces, and evidence artifacts enables rapid iteration without losing traceability in a mission-critical environment?",False,"What minimum set of requirements, interfaces, and evidence artifacts enables rapid iteration without losing traceability in a mission-critical environment?",What,DomainTopic=Software acquisition; satcom mission planning; USSF digital service | ScenarioType=Real program example (Evolved Strategic SATCOM mission planning software acquisition) | Hits=[],"What minimum set of requirements, interfaces, and evidence artifacts enables rapid iteration without losing traceability in a mission-critical environment?",False
DAU-DAMAG-2025-SATCOM-SW,DAU-DAMAG-2025-SATCOM-SW-Q03,2025,Defense Acquisition Magazine (DAU),Magazine/Trade,The Future of Space Force Software Acquisitions—A Case Study in Satellite Communications,"Barasha, L. S.; Jung, S.; Chong, C. K.",Software acquisition; satcom mission planning; USSF digital service,Real program example (Evolved Strategic SATCOM mission planning software acquisition),Acquisition strategy narrative; process lessons; stakeholder engagement patterns,Acquisition approach; process steps; lessons learned,Which measures and technical reviews are most predictive of mission impact for software changes in operational SATCOM contexts?,Secondary,Risk management & technical reviews,Measure; Verification; Validation; Risk; Test; Decision,,,Program case study narrative,Low-Medium (narrative; limited data),Open (web),Unclassified,Review cadence & criteria,Metrics-driven governance,https://www.dau.edu/library/damag/future-space-force-software,"Barasha, L. S., Jung, S., & Chong, C. K. (2025). The Future of Space Force Software Acquisitions—A Case Study in Satellite Communications. Defense Acquisition Magazine (DAU).",[],False,Which measures and technical reviews are most predictive of mission impact for software changes in operational SATCOM contexts?,False,Which measures and technical reviews are most predictive of mission impact for software changes in operational SATCOM contexts?,Which,DomainTopic=Software acquisition; satcom mission planning; USSF digital service | ScenarioType=Real program example (Evolved Strategic SATCOM mission planning software acquisition) | Hits=[],Which measures and technical reviews are most predictive of mission impact for software changes in operational SATCOM contexts?,True
JDMS-2025-UAV-RAIL-RECON,JDMS-2025-UAV-RAIL-RECON-Q01,2025,Journal of Defense Modeling and Simulation,Journal,A new approach to military logistical reconnaissance of railway infrastructures using UAV-based visual inspections and a tactical situation awareness framework,(See paper for full author list),Logistics; ISR; infrastructure assessment; UAV inspection,Operational logistics reconnaissance (railway infrastructure) with UAV inspection workflow,UAV-based inspection; situation awareness framework; workflow design,Recon framework; inspection workflow; situational awareness model,How can UAV-based inspection workflows and situational-awareness frameworks be composed to support rapid logistical reconnaissance of critical rail infrastructure under contested conditions?,Primary,Operational planning under uncertainty,ISR; Scenario; Task; Resource; Decision; Uncertainty; Architecture,Time-to-assess; detection accuracy; route availability,,Applied method paper,Medium,Open (PDF via SAGE),Unclassified,Recon workflow design,ISR workflow / SA framework,https://journals.sagepub.com/doi/pdf/10.1177/15485129241251699,(2025). A new approach to military logistical reconnaissance of railway infrastructures using UAV-based visual inspections and a tactical situation awareness framework. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/15485129241251699,"['UAV', 'rail']",True,How can platform-enabled inspection workflows and situational-awareness frameworks be composed to support rapid logistical reconnaissance of critical critical infrastructure under contested conditions?,True,How can platform-enabled inspection workflows and situational-awareness frameworks be composed to support rapid logistical reconnaissance of critical infrastructure under contested conditions?,How,"DomainTopic=Logistics; ISR; infrastructure assessment; UAV inspection | ScenarioType=Operational logistics reconnaissance (railway infrastructure) with UAV inspection workflow | Hits=['UAV', 'rail']",How can UAV-based inspection workflows and situational-awareness frameworks be composed to support rapid logistical reconnaissance of critical rail infrastructure under contested conditions?,False
JDMS-2025-UAV-RAIL-RECON,JDMS-2025-UAV-RAIL-RECON-Q02,2025,Journal of Defense Modeling and Simulation,Journal,A new approach to military logistical reconnaissance of railway infrastructures using UAV-based visual inspections and a tactical situation awareness framework,(See paper for full author list),Logistics; ISR; infrastructure assessment; UAV inspection,Operational logistics reconnaissance (railway infrastructure) with UAV inspection workflow,UAV-based inspection; situation awareness framework; workflow design,Recon framework; inspection workflow; situational awareness model,"What is the trade-off between inspection fidelity (image quality, coverage) and operational constraints (tempo, risk, energy, comms) for mission planning?",Primary,Resource tradeoffs & drivers,Tradeoff; Resource; Constraint; Risk; Schedule; Sensitivity,,,Applied method paper,Medium,Open (PDF via SAGE),Unclassified,UAV sortie planning,Trade-space / constraint analysis,https://journals.sagepub.com/doi/pdf/10.1177/15485129241251699,(2025). A new approach to military logistical reconnaissance of railway infrastructures using UAV-based visual inspections and a tactical situation awareness framework. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/15485129241251699,[],False,"What is the trade-off between inspection fidelity (image quality, coverage) and operational constraints (tempo, risk, energy, comms) for mission planning?",False,"What is the trade-off between inspection fidelity (image quality, coverage) and operational constraints (tempo, risk, energy, comms) for mission planning?",What,DomainTopic=Logistics; ISR; infrastructure assessment; UAV inspection | ScenarioType=Operational logistics reconnaissance (railway infrastructure) with UAV inspection workflow | Hits=[],"What is the trade-off between inspection fidelity (image quality, coverage) and operational constraints (tempo, risk, energy, comms) for mission planning?",False
JDMS-2025-UAV-RAIL-RECON,JDMS-2025-UAV-RAIL-RECON-Q03,2025,Journal of Defense Modeling and Simulation,Journal,A new approach to military logistical reconnaissance of railway infrastructures using UAV-based visual inspections and a tactical situation awareness framework,(See paper for full author list),Logistics; ISR; infrastructure assessment; UAV inspection,Operational logistics reconnaissance (railway infrastructure) with UAV inspection workflow,UAV-based inspection; situation awareness framework; workflow design,Recon framework; inspection workflow; situational awareness model,"Which interoperability interfaces (data formats, geospatial layers, reporting) are required to fuse UAV inspection outputs into C2/logistics planning systems?",Secondary,Interoperability & integration,Interoperability; Interface; Data; Architecture; Traceability; Standard,,,Applied method paper,Medium,Open (PDF via SAGE),Unclassified,Interface standardization,Data/architecture integration,https://journals.sagepub.com/doi/pdf/10.1177/15485129241251699,(2025). A new approach to military logistical reconnaissance of railway infrastructures using UAV-based visual inspections and a tactical situation awareness framework. Journal of Defense Modeling and Simulation. https://doi.org/10.1177/15485129241251699,"['UAV', 'C2']",True,"Which interoperability interfaces (data formats, geospatial layers, reporting) are required to fuse platform inspection outputs into command and control/logistics planning systems?",True,"Which interoperability interfaces (data formats, geospatial layers, reporting) are required to fuse platform inspection outputs into command and control/logistics planning systems?",Which,"DomainTopic=Logistics; ISR; infrastructure assessment; UAV inspection | ScenarioType=Operational logistics reconnaissance (railway infrastructure) with UAV inspection workflow | Hits=['UAV', 'C2']","Which interoperability interfaces (data formats, geospatial layers, reporting) are required to fuse UAV inspection outputs into C2/logistics planning systems?",False
